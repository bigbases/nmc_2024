{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 싱글모델로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from torch import distributed as dist\n",
    "from nmc.models import *\n",
    "from nmc.datasets import * \n",
    "from nmc.augmentations import get_train_augmentation, get_val_augmentation\n",
    "from nmc.losses import get_loss\n",
    "from nmc.schedulers import get_scheduler\n",
    "from nmc.optimizers import get_optimizer\n",
    "from nmc.utils.utils import fix_seeds, setup_cudnn, cleanup_ddp, setup_ddp\n",
    "from tools.val import evaluate_epi\n",
    "from nmc.utils.episodic_utils import * \n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda:1', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'FGMaxxVit', 'BACKBONE': 'FGMaxxVit', 'PRETRAINED': 'checkpoints/pretrained/maxvit_base_tf_512.in1k_pretrained_weights.pth', 'UNFREEZE': 'full', 'VERSION': 'ImageNet_APTOS_1024'}, 'DATASET': {'NAME': 'NMCSDataset', 'ROOT': '/data/nmc/processed_image', 'TRAIN_RATIO': 0.7, 'VALID_RATIO': 0.15, 'TEST_RATIO': 0.15}, 'TRAIN': {'IMAGE_SIZE': [512, 512], 'BATCH_SIZE': 32, 'EPOCHS': 100, 'EVAL_INTERVAL': 25, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'BCEWithLogitsLoss', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 0.0001, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'IMAGE_SIZE': [512, 512]}, 'TEST': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'FILE': 'assests/ade', 'IMAGE_SIZE': [512, 512], 'OVERLAY': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('../configs/NMC.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "print(cfg)\n",
    "fix_seeds(3407)\n",
    "setup_cudnn()\n",
    "gpu = setup_ddp()\n",
    "save_dir = Path(cfg['SAVE_DIR'])\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augmentation(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_test_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:1\n",
      "/data/nmc/processed_image/combined_images\n",
      "Target label: 0\n",
      "Train size: 677, Positive samples: 353\n",
      "Validation size: 145, Positive samples: 76\n",
      "Test size: 146, Positive samples: 76\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_mf1 = 0.0\n",
    "device = torch.device(cfg['DEVICE'])\n",
    "print(\"device : \", device)\n",
    "num_workers = mp.cpu_count()\n",
    "train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "image_size = [256,256]\n",
    "image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "train_transform = get_train_augmentation(image_size)\n",
    "val_test_transform = get_val_test_transform(image_size)\n",
    "batch_size = 32\n",
    "###################\n",
    "target_label = 0\n",
    "###################\n",
    "dataset = eval(dataset_cfg['NAME'])(\n",
    "    dataset_cfg['ROOT'] + '/combined_images',\n",
    "    dataset_cfg['TRAIN_RATIO'],\n",
    "    dataset_cfg['VALID_RATIO'],\n",
    "    dataset_cfg['TEST_RATIO'],\n",
    "    transform=None,\n",
    "    target_label=target_label\n",
    ")\n",
    "trainset, valset, testset = dataset.get_splits()\n",
    "trainset.transform = train_transform\n",
    "valset.transform = val_test_transform\n",
    "testset.transform = val_test_transform\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_32X8D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model definition (changed to binary classification)\n",
    "resnet = models.resnext101_32x8d(pretrained=True)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.Linear(num_ftrs, 1)\n",
    ")\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization\n",
    "weight_decay = 1e-5\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scaler = GradScaler(enabled=train_cfg['AMP'])\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=scaler is not None):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "        \n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().squeeze()\n",
    "            \n",
    "            if preds.dim() == 0:\n",
    "                preds = preds.unsqueeze(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scaler, device, epochs):\n",
    "    best_f1 = 0.0\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_f1)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'model/best_model_{}.pth'.format(target_label))\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        early_stopping(val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:19<00:00,  1.09it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6780\n",
      "Validation F1 Score: 0.7919\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:14<00:00,  1.42it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4548\n",
      "Validation F1 Score: 0.6833\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:14<00:00,  1.50it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3309\n",
      "Validation F1 Score: 0.7500\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2840\n",
      "Validation F1 Score: 0.7922\n",
      "New best model saved!\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:14<00:00,  1.42it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2044\n",
      "Validation F1 Score: 0.7564\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:15<00:00,  1.35it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 20.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2163\n",
      "Validation F1 Score: 0.8662\n",
      "New best model saved!\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:17<00:00,  1.23it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1472\n",
      "Validation F1 Score: 0.7841\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:15<00:00,  1.36it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 20.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1325\n",
      "Validation F1 Score: 0.7651\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:14<00:00,  1.44it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1061\n",
      "Validation F1 Score: 0.8293\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:13<00:00,  1.53it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1372\n",
      "Validation F1 Score: 0.8442\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:12<00:00,  1.66it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:08<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0846\n",
      "Validation F1 Score: 0.8302\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:11<00:00,  1.80it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:08<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0996\n",
      "Validation F1 Score: 0.8690\n",
      "New best model saved!\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.92it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:08<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0528\n",
      "Validation F1 Score: 0.8767\n",
      "New best model saved!\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:13<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0404\n",
      "Validation F1 Score: 0.8734\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:15<00:00,  1.39it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:05<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0344\n",
      "Validation F1 Score: 0.8790\n",
      "New best model saved!\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:17<00:00,  1.20it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 22.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0299\n",
      "Validation F1 Score: 0.8904\n",
      "New best model saved!\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  2.10it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:06<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0245\n",
      "Validation F1 Score: 0.8919\n",
      "New best model saved!\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:11<00:00,  1.80it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0177\n",
      "Validation F1 Score: 0.8535\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.95it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:08<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0099\n",
      "Validation F1 Score: 0.8742\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.91it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0260\n",
      "Validation F1 Score: 0.8243\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  2.00it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0366\n",
      "Validation F1 Score: 0.8535\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0634\n",
      "Validation F1 Score: 0.8344\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.93it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0666\n",
      "Validation F1 Score: 0.8944\n",
      "New best model saved!\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:12<00:00,  1.67it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0311\n",
      "Validation F1 Score: 0.7871\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.93it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0326\n",
      "Validation F1 Score: 0.8280\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:11<00:00,  1.89it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0183\n",
      "Validation F1 Score: 0.8267\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.99it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0234\n",
      "Validation F1 Score: 0.8571\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:11<00:00,  1.85it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:09<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0229\n",
      "Validation F1 Score: 0.8701\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:08<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0295\n",
      "Validation F1 Score: 0.7947\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0347\n",
      "Validation F1 Score: 0.8108\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.96it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0119\n",
      "Validation F1 Score: 0.8267\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.96it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:07<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0044\n",
      "Validation F1 Score: 0.8267\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:10<00:00,  1.98it/s]\n",
      "Evaluating: 100%|██████████| 145/145 [00:09<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0063\n",
      "Validation F1 Score: 0.8400\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 146/146 [00:06<00:00, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "# 정규화, lr스케쥴링, 데이터 증강, 조기종료, 배치정규화\n",
    "epochs = 100\n",
    "best_f1 = train_and_evaluate(resnet, trainloader, valloader, criterion, optimizer, scaler, device, epochs)\n",
    "\n",
    "print(f\"Training completed. Best F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "resnet.load_state_dict(torch.load('model/best_model_{}.pth'.format(target_label)))\n",
    "test_f1 = evaluate(resnet, testloader, device)\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 146/146 [00:07<00:00, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet.load_state_dict(torch.load('model/best_model_{}.pth'.format(target_label)))\n",
    "test_f1 = evaluate(resnet, testloader, device)\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def evaluate_and_save_misclassified(model, dataloader, device, save_dir):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    misclassified = []\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # 정규화에 사용된 평균과 표준편차 (이 값들은 사용한 transform에 맞게 조정해야 함)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().squeeze()\n",
    "            \n",
    "            if preds.dim() == 0:\n",
    "                preds = preds.unsqueeze(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # 잘못 분류된 이미지 저장\n",
    "            for j, (pred, label) in enumerate(zip(preds, labels)):\n",
    "                if pred != label:\n",
    "                    img = images[j].cpu()\n",
    "                    \n",
    "                    # 정규화 해제\n",
    "                    img = denormalize(img, mean, std)\n",
    "                    \n",
    "                    # [0, 1] 범위의 float 텐서를 [0, 255] 범위의 uint8로 변환\n",
    "                    img = (img * 255).byte()\n",
    "                    \n",
    "                    img = transforms.ToPILImage()(img)\n",
    "                    img_name = f\"misclassified_{i}_{j}_pred{pred.item()}_true{label.item()}.png\"\n",
    "                    img.save(os.path.join(save_dir, img_name))\n",
    "                    misclassified.append((i, j, pred.item(), label.item()))\n",
    "    \n",
    "    return all_preds, all_labels, misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnext101_32x8d()\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.Linear(num_ftrs, 1)\n",
    ")\n",
    "resnet.load_state_dict(torch.load('model/best_model_{}.pth'.format(target_label), map_location=device))\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 146/146 [00:07<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassified images: 17\n",
      "Misclassified images saved in: misclassified_images\n",
      "False Positives: 8\n",
      "False Negatives: 9\n",
      "\n",
      "Some examples of misclassified images:\n",
      "Image 1: Batch 1, Index 0, Predicted 1, True label 0.0\n",
      "Image 2: Batch 3, Index 0, Predicted 1, True label 0.0\n",
      "Image 3: Batch 4, Index 0, Predicted 1, True label 0.0\n",
      "Image 4: Batch 19, Index 0, Predicted 1, True label 0.0\n",
      "Image 5: Batch 46, Index 0, Predicted 1, True label 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "# 평가 및 잘못 분류된 이미지 저장\n",
    "save_dir = \"misclassified_images\"\n",
    "all_preds, all_labels, misclassified = evaluate_and_save_misclassified(resnet, testloader, device, save_dir)\n",
    "\n",
    "print(f\"Total misclassified images: {len(misclassified)}\")\n",
    "print(\"Misclassified images saved in:\", save_dir)\n",
    "\n",
    "# 잘못 분류된 이미지 분석\n",
    "false_positives = sum(1 for pred, label in zip(all_preds, all_labels) if pred == 1 and label == 0)\n",
    "false_negatives = sum(1 for pred, label in zip(all_preds, all_labels) if pred == 0 and label == 1)\n",
    "\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "# 몇 개의 잘못 분류된 이미지 예시 출력\n",
    "print(\"\\nSome examples of misclassified images:\")\n",
    "for i, (batch, index, pred, true) in enumerate(misclassified[:5]):  # 처음 5개만 출력\n",
    "    print(f\"Image {i+1}: Batch {batch}, Index {index}, Predicted {pred}, True label {true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerGradCAM:\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.activations = {}\n",
    "        self.gradients = {}\n",
    "        \n",
    "        for name, layer in self.target_layers:\n",
    "            layer.register_forward_hook(self.save_activation(name))\n",
    "            layer.register_backward_hook(self.save_gradient(name))\n",
    "    \n",
    "    def save_activation(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    def save_gradient(self, name):\n",
    "        def hook(module, grad_input, grad_output):\n",
    "            self.gradients[name] = grad_output[0]\n",
    "        return hook\n",
    "    \n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        self.model.eval()\n",
    "        model_output = self.model(input_image)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        model_output[0, target_class].backward()\n",
    "        \n",
    "        heatmaps = []\n",
    "        for name, _ in self.target_layers:\n",
    "            activation = self.activations[name]\n",
    "            gradient = self.gradients[name]\n",
    "            \n",
    "            pooled_gradients = torch.mean(gradient, dim=[0, 2, 3])\n",
    "            heatmap = torch.sum(activation * pooled_gradients.unsqueeze(1).unsqueeze(2), dim=1)\n",
    "            heatmap = F.relu(heatmap)\n",
    "            heatmap = heatmap / (torch.max(heatmap) + 1e-10)\n",
    "            heatmap = F.interpolate(heatmap.unsqueeze(0).unsqueeze(0), \n",
    "                                    size=input_image.shape[2:],\n",
    "                                    mode='bilinear', \n",
    "                                    align_corners=False)\n",
    "            heatmaps.append(heatmap)\n",
    "        \n",
    "        return torch.mean(torch.stack(heatmaps), dim=0)[0, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [\n",
    "    ('layer2', resnet.layer2[-1]),\n",
    "    ('layer3', resnet.layer3[-1]),\n",
    "    ('layer4', resnet.layer4[-1])\n",
    "]\n",
    "grad_cam = MultiLayerGradCAM(resnet, target_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradcam(image, label, prediction, index, save_path):\n",
    "    try:\n",
    "        # 이미지를 CPU로 이동하고 numpy 배열로 변환\n",
    "        image_np = image.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # 정규화 해제\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image_np = std * image_np + mean\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "        # GradCAM 생성\n",
    "        input_tensor = image.unsqueeze(0).to(device)\n",
    "        heatmap = grad_cam.generate_cam(input_tensor)\n",
    "        \n",
    "        # Heatmap을 원본 이미지 크기로 리사이즈\n",
    "        heatmap = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))\n",
    "        \n",
    "        # Heatmap을 RGB로 변환\n",
    "        heatmap_rgb = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "        heatmap_rgb = cv2.cvtColor(heatmap_rgb, cv2.COLOR_BGR2RGB) / 255.0\n",
    "        \n",
    "        # Heatmap과 원본 이미지 합성\n",
    "        cam_image = (heatmap_rgb * 0.4 + image_np * 0.6)\n",
    "        cam_image = cam_image / np.max(cam_image)\n",
    "\n",
    "        # 결과 시각화 및 저장\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        ax1.imshow(image_np)\n",
    "        ax1.set_title(f'Original (True: {label}, Pred: {prediction})')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(heatmap, cmap='jet')\n",
    "        ax2.set_title('Grad-CAM Heatmap')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        ax3.imshow(cam_image)\n",
    "        ax3.set_title('Grad-CAM Overlay')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {index}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:   6%|▌         | 9/146 [00:00<00:07, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 5_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 7_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  12%|█▏        | 18/146 [00:00<00:05, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 14_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 16_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 17_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  18%|█▊        | 27/146 [00:01<00:04, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 22_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 26_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 27_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 28_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  24%|██▍       | 35/146 [00:01<00:04, 27.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 31_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 32_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 34_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  28%|██▊       | 41/146 [00:01<00:04, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 38_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 40_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  32%|███▏      | 47/146 [00:02<00:04, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 43_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 44_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 45_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 47_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  36%|███▋      | 53/146 [00:02<00:03, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 49_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 51_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 52_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 53_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  41%|████      | 60/146 [00:02<00:03, 26.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 54_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 55_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 58_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  44%|████▍     | 64/146 [00:02<00:02, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 60_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 63_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 65_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  49%|████▊     | 71/146 [00:02<00:02, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 67_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 68_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 70_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 71_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  53%|█████▎    | 78/146 [00:03<00:02, 25.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 72_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 73_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 77_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  58%|█████▊    | 84/146 [00:03<00:02, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 80_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 82_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 84_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  60%|█████▉    | 87/146 [00:03<00:02, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 85_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 86_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 88_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  64%|██████▍   | 94/146 [00:03<00:02, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 90_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 91_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 93_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 94_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  68%|██████▊   | 100/146 [00:04<00:02, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 97_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 98_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 99_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 100_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 101_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  73%|███████▎  | 106/146 [00:04<00:01, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 102_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 103_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 104_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 105_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  77%|███████▋  | 112/146 [00:04<00:01, 23.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 107_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 108_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 109_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  79%|███████▉  | 115/146 [00:04<00:01, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 112_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 113_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 115_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  83%|████████▎ | 121/146 [00:05<00:01, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 117_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 119_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 120_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  89%|████████▉ | 130/146 [00:05<00:00, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 125_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 128_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 129_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  93%|█████████▎| 136/146 [00:05<00:00, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 130_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 132_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 133_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 134_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM:  96%|█████████▌| 140/146 [00:05<00:00, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 137_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 139_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 140_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 141_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM: 100%|██████████| 146/146 [00:06<00:00, 23.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image 142_0: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "Error processing image 145_0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM: 100%|██████████| 146/146 [00:06<00:00, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 47.95%\n",
      "Grad-CAM visualizations have been saved in: gradcam_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# GradCAM 적용 및 시각화\n",
    "gradcam_dir = \"gradcam_results\"\n",
    "os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(testloader, desc=\"Generating Grad-CAM\")):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        for i in range(images.size(0)):\n",
    "            if predicted[i] != labels[i]:  # 잘못 분류된 이미지에 대해서만\n",
    "                save_path = os.path.join(gradcam_dir, f\"gradcam_batch{batch_idx}_img{i}_true{labels[i]}_pred{predicted[i]}.png\")\n",
    "                visualize_gradcam(images[i], labels[i].item(), predicted[i].item(), f\"{batch_idx}_{i}\", save_path)\n",
    "\n",
    "print(f\"Test Accuracy: {100.*correct/total:.2f}%\")\n",
    "print(\"Grad-CAM visualizations have been saved in:\", gradcam_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
