{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 싱글모델로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from torch import distributed as dist\n",
    "from nmc.models import *\n",
    "from nmc.datasets import * \n",
    "from nmc.augmentations import get_train_augmentation, get_val_augmentation\n",
    "from nmc.losses import get_loss\n",
    "from nmc.schedulers import get_scheduler\n",
    "from nmc.optimizers import get_optimizer\n",
    "from nmc.utils.utils import fix_seeds, setup_cudnn, cleanup_ddp, setup_ddp\n",
    "from tools.val import evaluate_epi\n",
    "from nmc.utils.episodic_utils import * \n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda:0', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'EfficientNetV2MModel', 'BACKBONE': 'EfficientNetV2', 'PRETRAINED': '/workspace/jhmoon/nmc_2024/checkpoints/pretrained/tf_efficientnetv2_m_weights.pth', 'UNFREEZE': 'full', 'VERSION': '384_32'}, 'DATASET': {'NAME': 'APTOSDataset', 'ROOT': '/data/public_data/aptos', 'TRAIN_RATIO': 0.7, 'VALID_RATIO': 0.15, 'TEST_RATIO': 0.15}, 'TRAIN': {'IMAGE_SIZE': [384, 384], 'BATCH_SIZE': 32, 'EPOCHS': 100, 'EVAL_INTERVAL': 25, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'CrossEntropy', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 0.001, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.APTOS.pth', 'IMAGE_SIZE': [384, 384]}, 'TEST': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.APTOS.pth', 'FILE': 'assests/ade', 'IMAGE_SIZE': [384, 384], 'OVERLAY': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('../configs/APTOS.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "print(cfg)\n",
    "fix_seeds(3407)\n",
    "setup_cudnn()\n",
    "gpu = setup_ddp()\n",
    "save_dir = Path(cfg['SAVE_DIR'])\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augmentation(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_test_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 라벨 비율은 배치내에서 1대1이 되도록 조정\n",
    "class BinaryBalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, target_class):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.target_class = target_class\n",
    "        \n",
    "        # 데이터셋에서 레이블 추출\n",
    "        if hasattr(dataset, 'labels'):\n",
    "            self.labels = dataset.labels\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        elif hasattr(dataset, 'targets'):\n",
    "            self.labels = dataset.targets\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        else:\n",
    "            try:\n",
    "                self.labels = [sample[1] for sample in dataset]\n",
    "                if isinstance(self.labels[0], np.ndarray):\n",
    "                    self.labels = torch.from_numpy(np.array(self.labels))\n",
    "                else:\n",
    "                    self.labels = torch.tensor(self.labels)\n",
    "            except:\n",
    "                raise ValueError(\"Cannot access labels from dataset\")\n",
    "        \n",
    "        # 타겟 클래스와 나머지 클래스의 인덱스 저장\n",
    "        if len(self.labels.shape) > 1:\n",
    "            self.target_indices = torch.where(self.labels[:, target_class] == 1)[0]\n",
    "            self.other_indices = torch.where(self.labels[:, target_class] == 0)[0]\n",
    "        else:\n",
    "            self.target_indices = torch.where(self.labels == target_class)[0]\n",
    "            self.other_indices = torch.where(self.labels != target_class)[0]\n",
    "        \n",
    "        # 각 배치에서의 샘플 수 계산\n",
    "        self.samples_per_class = batch_size // 2  # 1:1 비율\n",
    "        \n",
    "        self.n_batches = len(self.dataset) // batch_size\n",
    "        if len(self.dataset) % batch_size != 0:\n",
    "            self.n_batches += 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for _ in range(self.n_batches):\n",
    "            batch_indices = []\n",
    "            \n",
    "            # 타겟 클래스에서 샘플링\n",
    "            target_selected = self.target_indices[\n",
    "                torch.randint(len(self.target_indices), \n",
    "                            (self.samples_per_class,))\n",
    "            ]\n",
    "            batch_indices.extend(target_selected.tolist())\n",
    "            \n",
    "            # 다른 클래스들에서 샘플링\n",
    "            other_selected = self.other_indices[\n",
    "                torch.randint(len(self.other_indices), \n",
    "                            (self.samples_per_class,))\n",
    "            ]\n",
    "            batch_indices.extend(other_selected.tolist())\n",
    "            \n",
    "            # 배치 셔플\n",
    "            random.shuffle(batch_indices)\n",
    "            \n",
    "            # 배치 크기에 맞게 자르기\n",
    "            if len(batch_indices) > self.batch_size:\n",
    "                batch_indices = batch_indices[:self.batch_size]\n",
    "            \n",
    "            yield batch_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device, target_label_idx):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        # 특정 라벨만 추출\n",
    "        target_labels = labels[:, target_label_idx].float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=scaler is not None):\n",
    "            outputs = model(images)\n",
    "            # 차원 처리\n",
    "            if len(outputs.shape) == 2:\n",
    "                outputs = outputs.squeeze(1)  # [batch_size, 1] -> [batch_size]\n",
    "            loss = criterion(outputs, target_labels)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, target_label_idx):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            # 특정 라벨만 추출\n",
    "            target_labels = labels[:, target_label_idx].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 차원을 명시적으로 처리\n",
    "            if len(outputs.shape) == 2:\n",
    "                outputs = outputs.squeeze(1)  # [batch_size, 1] -> [batch_size]\n",
    "            \n",
    "            # 예측값 계산 (배치 차원 유지)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            \n",
    "            # 배치 단위로 저장하되 차원 명시적 처리\n",
    "            all_preds.append(preds.cpu().numpy().reshape(-1))  # 1차원으로 펼치기\n",
    "            all_labels.append(target_labels.cpu().numpy().reshape(-1))\n",
    "    \n",
    "    # 배치 단위의 리스트를 하나의 numpy array로 변환\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    \n",
    "    return f1, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scaler, device, epochs, target_label_idx):\n",
    "    best_f1 = 0.0\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device, target_label_idx)\n",
    "        val_f1, val_acc, val_prec, val_rec = evaluate(model, val_loader, device, target_label_idx)\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Metrics:\")\n",
    "        print(f\"  F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"  Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"  Precision: {val_prec:.4f}\")\n",
    "        print(f\"  Recall: {val_rec:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_f1)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), f'model/singlelabel_finetuning/best_model_label_{target_label_idx}_aptos_cnn.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        early_stopping(val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [01:00<00:00,  1.34it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0630\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9870\n",
      "  Accuracy: 0.9872\n",
      "  Precision: 0.9925\n",
      "  Recall: 0.9815\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.69it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0293\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9907\n",
      "  Accuracy: 0.9909\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.9815\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:37<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0114\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9607\n",
      "  Accuracy: 0.9599\n",
      "  Precision: 0.9308\n",
      "  Recall: 0.9926\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:47<00:00,  1.69it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0287\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9850\n",
      "  Accuracy: 0.9854\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.9705\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0097\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9871\n",
      "  Accuracy: 0.9872\n",
      "  Precision: 0.9889\n",
      "  Recall: 0.9852\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:47<00:00,  1.71it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0072\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9796\n",
      "  Accuracy: 0.9800\n",
      "  Precision: 0.9851\n",
      "  Recall: 0.9742\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0069\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9796\n",
      "  Accuracy: 0.9800\n",
      "  Precision: 0.9851\n",
      "  Recall: 0.9742\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:41<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0050\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9754\n",
      "  Accuracy: 0.9763\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.9520\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:53<00:00,  1.50it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:30<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0078\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9832\n",
      "  Accuracy: 0.9836\n",
      "  Precision: 0.9925\n",
      "  Recall: 0.9742\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.54it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0023\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9870\n",
      "  Accuracy: 0.9872\n",
      "  Precision: 0.9962\n",
      "  Recall: 0.9779\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:46<00:00,  1.73it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:39<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0037\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9815\n",
      "  Accuracy: 0.9818\n",
      "  Precision: 0.9851\n",
      "  Recall: 0.9779\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.56it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.37it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0025\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.9851\n",
      "  Accuracy: 0.9854\n",
      "  Precision: 0.9925\n",
      "  Recall: 0.9779\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.9907\n",
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.58it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:28<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2854\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6184\n",
      "  Accuracy: 0.8944\n",
      "  Precision: 0.4845\n",
      "  Recall: 0.8545\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:56<00:00,  1.44it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:25<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1031\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6016\n",
      "  Accuracy: 0.9107\n",
      "  Precision: 0.5441\n",
      "  Recall: 0.6727\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:46<00:00,  1.75it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:22<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0675\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5849\n",
      "  Accuracy: 0.9199\n",
      "  Precision: 0.6078\n",
      "  Recall: 0.5636\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:31<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0702\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5192\n",
      "  Accuracy: 0.9089\n",
      "  Precision: 0.5510\n",
      "  Recall: 0.4909\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:59<00:00,  1.36it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:23<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0344\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5926\n",
      "  Accuracy: 0.9199\n",
      "  Precision: 0.6038\n",
      "  Recall: 0.5818\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.65it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:30<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0324\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5607\n",
      "  Accuracy: 0.9144\n",
      "  Precision: 0.5769\n",
      "  Recall: 0.5455\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:53<00:00,  1.51it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:21<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0268\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5664\n",
      "  Accuracy: 0.9107\n",
      "  Precision: 0.5517\n",
      "  Recall: 0.5818\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:54<00:00,  1.48it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:31<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0125\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5794\n",
      "  Accuracy: 0.9180\n",
      "  Precision: 0.5962\n",
      "  Recall: 0.5636\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:46<00:00,  1.74it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:32<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0095\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5872\n",
      "  Accuracy: 0.9180\n",
      "  Precision: 0.5926\n",
      "  Recall: 0.5818\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.54it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0098\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5872\n",
      "  Accuracy: 0.9180\n",
      "  Precision: 0.5926\n",
      "  Recall: 0.5818\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:47<00:00,  1.71it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:27<00:00,  6.28it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0099\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6000\n",
      "  Accuracy: 0.9199\n",
      "  Precision: 0.6000\n",
      "  Recall: 0.6000\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.6184\n",
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:53<00:00,  1.52it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3091\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7433\n",
      "  Accuracy: 0.8251\n",
      "  Precision: 0.6205\n",
      "  Recall: 0.9267\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:40<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1897\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7762\n",
      "  Accuracy: 0.8561\n",
      "  Precision: 0.6749\n",
      "  Recall: 0.9133\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:29<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1362\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7701\n",
      "  Accuracy: 0.8597\n",
      "  Precision: 0.6973\n",
      "  Recall: 0.8600\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:56<00:00,  1.43it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:45<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1093\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7664\n",
      "  Accuracy: 0.8634\n",
      "  Precision: 0.7193\n",
      "  Recall: 0.8200\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:46<00:00,  1.76it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:34<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0814\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7716\n",
      "  Accuracy: 0.8652\n",
      "  Precision: 0.7184\n",
      "  Recall: 0.8333\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [01:03<00:00,  1.28it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:34<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0615\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7834\n",
      "  Accuracy: 0.8670\n",
      "  Precision: 0.7059\n",
      "  Recall: 0.8800\n",
      "New best model saved!\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0764\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7732\n",
      "  Accuracy: 0.8707\n",
      "  Precision: 0.7423\n",
      "  Recall: 0.8067\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:57<00:00,  1.42it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0431\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7750\n",
      "  Accuracy: 0.8689\n",
      "  Precision: 0.7294\n",
      "  Recall: 0.8267\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.65it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0413\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7628\n",
      "  Accuracy: 0.8652\n",
      "  Precision: 0.7346\n",
      "  Recall: 0.7933\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:58<00:00,  1.39it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0512\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7677\n",
      "  Accuracy: 0.8743\n",
      "  Precision: 0.7755\n",
      "  Recall: 0.7600\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0387\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7566\n",
      "  Accuracy: 0.8652\n",
      "  Precision: 0.7468\n",
      "  Recall: 0.7667\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [01:00<00:00,  1.33it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:37<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0416\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7286\n",
      "  Accuracy: 0.8616\n",
      "  Precision: 0.7846\n",
      "  Recall: 0.6800\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.63it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:40<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0334\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7818\n",
      "  Accuracy: 0.8780\n",
      "  Precision: 0.7643\n",
      "  Recall: 0.8000\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [01:00<00:00,  1.33it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:41<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0212\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7682\n",
      "  Accuracy: 0.8725\n",
      "  Precision: 0.7632\n",
      "  Recall: 0.7733\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:46<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0194\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7708\n",
      "  Accuracy: 0.8743\n",
      "  Precision: 0.7682\n",
      "  Recall: 0.7733\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:54<00:00,  1.47it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.89it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0168\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.7682\n",
      "  Accuracy: 0.8725\n",
      "  Precision: 0.7632\n",
      "  Recall: 0.7733\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.7834\n",
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:31<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1856\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3636\n",
      "  Accuracy: 0.9362\n",
      "  Precision: 0.3846\n",
      "  Recall: 0.3448\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:58<00:00,  1.39it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0714\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3704\n",
      "  Accuracy: 0.9381\n",
      "  Precision: 0.4000\n",
      "  Recall: 0.3448\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.62it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:31<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0632\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3077\n",
      "  Accuracy: 0.9344\n",
      "  Precision: 0.3478\n",
      "  Recall: 0.2759\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:55<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0348\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.4333\n",
      "  Accuracy: 0.9381\n",
      "  Precision: 0.4194\n",
      "  Recall: 0.4483\n",
      "New best model saved!\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0332\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.4127\n",
      "  Accuracy: 0.9326\n",
      "  Precision: 0.3824\n",
      "  Recall: 0.4483\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:55<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0291\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.4400\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.5238\n",
      "  Recall: 0.3793\n",
      "New best model saved!\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0273\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.2128\n",
      "  Accuracy: 0.9326\n",
      "  Precision: 0.2778\n",
      "  Recall: 0.1724\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:39<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0263\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.2222\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.5714\n",
      "  Recall: 0.1379\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:58<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:34<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0155\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3077\n",
      "  Accuracy: 0.9508\n",
      "  Precision: 0.6000\n",
      "  Recall: 0.2069\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.62it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:39<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0228\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.2927\n",
      "  Accuracy: 0.9472\n",
      "  Precision: 0.5000\n",
      "  Recall: 0.2069\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:57<00:00,  1.41it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:31<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0232\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3111\n",
      "  Accuracy: 0.9435\n",
      "  Precision: 0.4375\n",
      "  Recall: 0.2414\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:39<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0192\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3415\n",
      "  Accuracy: 0.9508\n",
      "  Precision: 0.5833\n",
      "  Recall: 0.2414\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [01:03<00:00,  1.27it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0136\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3333\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.5385\n",
      "  Recall: 0.2414\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0148\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.3000\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.5455\n",
      "  Recall: 0.2069\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0095\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.2857\n",
      "  Accuracy: 0.9454\n",
      "  Precision: 0.4615\n",
      "  Recall: 0.2069\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:39<00:00,  5.53it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0119\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.2857\n",
      "  Accuracy: 0.9454\n",
      "  Precision: 0.4615\n",
      "  Recall: 0.2069\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.4400\n",
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:54<00:00,  1.48it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3001\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5490\n",
      "  Accuracy: 0.9162\n",
      "  Precision: 0.4828\n",
      "  Recall: 0.6364\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.68it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1124\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5641\n",
      "  Accuracy: 0.9381\n",
      "  Precision: 0.6471\n",
      "  Recall: 0.5000\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:29<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0562\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6341\n",
      "  Accuracy: 0.9454\n",
      "  Precision: 0.6842\n",
      "  Recall: 0.5909\n",
      "New best model saved!\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:53<00:00,  1.51it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0628\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5747\n",
      "  Accuracy: 0.9326\n",
      "  Precision: 0.5814\n",
      "  Recall: 0.5682\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.63it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0464\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6582\n",
      "  Accuracy: 0.9508\n",
      "  Precision: 0.7429\n",
      "  Recall: 0.5909\n",
      "New best model saved!\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:53<00:00,  1.51it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:37<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0352\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5789\n",
      "  Accuracy: 0.9417\n",
      "  Precision: 0.6875\n",
      "  Recall: 0.5000\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:49<00:00,  1.63it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:46<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0364\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6667\n",
      "  Accuracy: 0.9508\n",
      "  Precision: 0.7297\n",
      "  Recall: 0.6136\n",
      "New best model saved!\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.56it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0196\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6667\n",
      "  Accuracy: 0.9508\n",
      "  Precision: 0.7297\n",
      "  Recall: 0.6136\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:50<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:44<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0246\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.5263\n",
      "  Accuracy: 0.9344\n",
      "  Precision: 0.6250\n",
      "  Recall: 0.4545\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:56<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:35<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0298\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6667\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.7000\n",
      "  Recall: 0.6364\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:48<00:00,  1.67it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:44<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0277\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6234\n",
      "  Accuracy: 0.9472\n",
      "  Precision: 0.7273\n",
      "  Recall: 0.5455\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:51<00:00,  1.57it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:33<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0128\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6234\n",
      "  Accuracy: 0.9472\n",
      "  Precision: 0.7273\n",
      "  Recall: 0.5455\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.54it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0252\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6500\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.7222\n",
      "  Recall: 0.5909\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:58<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0124\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6154\n",
      "  Accuracy: 0.9454\n",
      "  Precision: 0.7059\n",
      "  Recall: 0.5455\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:54<00:00,  1.47it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:45<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0201\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6329\n",
      "  Accuracy: 0.9472\n",
      "  Precision: 0.7143\n",
      "  Recall: 0.5682\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:56<00:00,  1.44it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0097\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6154\n",
      "  Accuracy: 0.9454\n",
      "  Precision: 0.7059\n",
      "  Recall: 0.5455\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:52<00:00,  1.54it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:45<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0109\n",
      "Validation Metrics:\n",
      "  F1 Score: 0.6410\n",
      "  Accuracy: 0.9490\n",
      "  Precision: 0.7353\n",
      "  Recall: 0.5682\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ncm_aptos_labels = [[0],[2],[1],[1,2],[5,6]]\n",
    "for target_label_idx in range(5):\n",
    "    \n",
    "    start = time.time()\n",
    "    best_mf1 = 0.0\n",
    "    device = torch.device(cfg['DEVICE'])\n",
    "    print(\"device : \", device)\n",
    "    num_workers = mp.cpu_count()\n",
    "    train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "    dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "    loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "    epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "    image_size = [256,256]\n",
    "    image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "    train_transform = get_train_augmentation(image_size)\n",
    "    val_test_transform = get_val_test_transform(image_size)\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    dataset = eval(dataset_cfg['NAME'])(\n",
    "        dataset_cfg['ROOT'] + '/combined_images',\n",
    "        dataset_cfg['TRAIN_RATIO'],\n",
    "        dataset_cfg['VALID_RATIO'],\n",
    "        dataset_cfg['TEST_RATIO'],\n",
    "        transform=None\n",
    "    )\n",
    "    trainset, valset, testset = dataset.get_splits()\n",
    "    trainset.transform = train_transform\n",
    "    valset.transform = val_test_transform\n",
    "    testset.transform = val_test_transform\n",
    "\n",
    "    # DataLoader 수정\n",
    "    trainloader = DataLoader(\n",
    "        trainset, \n",
    "        batch_sampler=BinaryBalancedBatchSampler(trainset, batch_size=batch_size,target_class = target_label_idx),\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    #trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "    valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "    testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "\n",
    "    # Model definition (changed to binary classification)\n",
    "    model = models.efficientnet_v2_m(pretrained=True)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    num_targets = len(ncm_aptos_labels[target_label_idx])\n",
    "    \n",
    "    if num_targets == 1:\n",
    "        # 단일 레이블 케이스 (기존 코드와 동일)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_ftrs),\n",
    "            nn.Linear(num_ftrs, 1)\n",
    "        )\n",
    "        model.load_state_dict(torch.load(f'model/singlelabel/best_model_label_{ncm_aptos_labels[target_label_idx][0]}_nmc_cnn.pth'))\n",
    "    else:\n",
    "        # 다중 레이블 케이스\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_ftrs),\n",
    "            nn.Linear(num_ftrs, num_targets)\n",
    "        )\n",
    "        model.load_state_dict(torch.load(f'model/singlelabel/best_model_labels_{\"-\".join(map(str,ncm_aptos_labels[target_label_idx]))}_nmc_cnn.pth'))\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_ftrs),\n",
    "        nn.Linear(num_ftrs, 1)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # L2 regularization\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scaler = GradScaler(enabled=train_cfg['AMP'])\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    # Main execution code\n",
    "    epochs = 100\n",
    "    # 학습하고자 하는 라벨 인덱스\n",
    "\n",
    "\n",
    "    best_f1 = train_and_evaluate(\n",
    "        model, \n",
    "        trainloader, \n",
    "        valloader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        scaler, \n",
    "        device, \n",
    "        epochs,\n",
    "        target_label_idx\n",
    "    )\n",
    "\n",
    "    print(f\"Training completed. Best F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_mf1 = 0.0\n",
    "device = torch.device(cfg['DEVICE'])\n",
    "print(\"device : \", device)\n",
    "num_workers = mp.cpu_count()\n",
    "train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "image_size = [256,256]\n",
    "image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "train_transform = get_train_augmentation(image_size)\n",
    "val_test_transform = get_val_test_transform(image_size)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataset = eval(dataset_cfg['NAME'])(\n",
    "    dataset_cfg['ROOT'] + '/combined_images',\n",
    "    dataset_cfg['TRAIN_RATIO'],\n",
    "    dataset_cfg['VALID_RATIO'],\n",
    "    dataset_cfg['TEST_RATIO'],\n",
    "    transform=None\n",
    ")\n",
    "trainset, valset, testset = dataset.get_splits()\n",
    "trainset.transform = train_transform\n",
    "valset.transform = val_test_transform\n",
    "testset.transform = val_test_transform\n",
    "\n",
    "#trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:32<00:00,  5.94it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  F1 Score: 0.9851\n",
      "  Accuracy: 0.9855\n",
      "  Precision: 0.9962\n",
      "  Recall: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:36<00:00,  5.72it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  F1 Score: 0.5417\n",
      "  Accuracy: 0.8800\n",
      "  Precision: 0.4432\n",
      "  Recall: 0.6964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:28<00:00,  6.25it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  F1 Score: 0.7600\n",
      "  Accuracy: 0.8473\n",
      "  Precision: 0.6650\n",
      "  Recall: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:29<00:00,  6.16it/s]\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  F1 Score: 0.4483\n",
      "  Accuracy: 0.9418\n",
      "  Precision: 0.4483\n",
      "  Recall: 0.4483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:28<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  F1 Score: 0.6000\n",
      "  Accuracy: 0.9418\n",
      "  Precision: 0.6667\n",
      "  Recall: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for target_label_idx in range(5):\n",
    "    # Model definition (changed to binary classification)\n",
    "    efficientnet = models.efficientnet_v2_m(pretrained=True)\n",
    "    num_ftrs = efficientnet.classifier[1].in_features\n",
    "    \n",
    "    efficientnet.classifier = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_ftrs),\n",
    "        nn.Linear(num_ftrs, 1)\n",
    "    )\n",
    "    efficientnet = efficientnet.to(device)\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    efficientnet.load_state_dict(torch.load(f'model/singlelabel_finetuning/best_model_label_{target_label_idx}_aptos_cnn.pth'))\n",
    "    test_f1, test_acc, test_prec, test_rec = evaluate(efficientnet, testloader, device, target_label_idx)\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Precision: {test_prec:.4f}\")\n",
    "    print(f\"  Recall: {test_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
