{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from torch import distributed as dist\n",
    "from nmc.models import *\n",
    "from nmc.datasets import * \n",
    "from nmc.augmentations import get_train_augmentation, get_val_augmentation\n",
    "from nmc.losses import get_loss\n",
    "from nmc.schedulers import get_scheduler\n",
    "from nmc.optimizers import get_optimizer\n",
    "from nmc.utils.utils import fix_seeds, setup_cudnn, cleanup_ddp, setup_ddp\n",
    "from tools.val import evaluate_epi\n",
    "from nmc.utils.episodic_utils import * \n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda:1', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'FGMaxxVit', 'BACKBONE': 'FGMaxxVit', 'PRETRAINED': 'checkpoints/pretrained/maxvit_base_tf_512.in1k_pretrained_weights.pth', 'UNFREEZE': 'full', 'VERSION': 'ImageNet_APTOS_1024'}, 'DATASET': {'NAME': 'NMCDataset', 'ROOT': '/data/nmc/processed_image', 'TRAIN_RATIO': 0.7, 'VALID_RATIO': 0.15, 'TEST_RATIO': 0.15}, 'TRAIN': {'IMAGE_SIZE': [512, 512], 'BATCH_SIZE': 32, 'EPOCHS': 100, 'EVAL_INTERVAL': 25, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'BCEWithLogitsLoss', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 0.001, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'IMAGE_SIZE': [512, 512]}, 'TEST': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'FILE': 'assests/ade', 'IMAGE_SIZE': [512, 512], 'OVERLAY': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('configs/NMC.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "print(cfg)\n",
    "fix_seeds(3407)\n",
    "setup_cudnn()\n",
    "gpu = setup_ddp()\n",
    "save_dir = Path(cfg['SAVE_DIR'])\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(dataloader):\n",
    "    all_labels = []\n",
    "    for _, labels in tqdm(dataloader, desc=\"Extracting labels\"):\n",
    "        all_labels.append(labels.numpy())\n",
    "    return np.vstack(all_labels)\n",
    "def calculate_mutual_info_matrix(label_matrix):\n",
    "    n_labels = label_matrix.shape[1]\n",
    "    mi_matrix = np.zeros((n_labels, n_labels))\n",
    "    for i in range(n_labels):\n",
    "        for j in range(i, n_labels):\n",
    "            mi = mutual_info_score(label_matrix[:, i], label_matrix[:, j])\n",
    "            mi_matrix[i, j] = mi\n",
    "            mi_matrix[j, i] = mi\n",
    "    return mi_matrix\n",
    "def plot_heatmap(matrix, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=False, cmap='coolwarm')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "def analyze_trainloader_labels(trainloader):\n",
    "    # 라벨 추출\n",
    "    label_matrix = extract_labels(trainloader)\n",
    "\n",
    "    # 상호 정보량 매트릭스 계산 및 시각화\n",
    "    mi_matrix = calculate_mutual_info_matrix(label_matrix)\n",
    "    plot_heatmap(mi_matrix, 'Label Mutual Information Matrix')\n",
    "    return mi_matrix\n",
    "def select_most_independent_labels(mi_matrix):\n",
    "    linkage = hierarchy.linkage(mi_matrix, method='average')\n",
    "    \n",
    "    n_labels = mi_matrix.shape[0]\n",
    "    ordered_labels = []\n",
    "    remaining_clusters = list(range(2 * n_labels - 1))\n",
    "    \n",
    "    while len(ordered_labels) < n_labels:\n",
    "        heights = [linkage[i-n_labels, 2] if i >= n_labels else 0 for i in remaining_clusters]\n",
    "        max_height_idx = np.argmax(heights)\n",
    "        selected_cluster = remaining_clusters[max_height_idx]\n",
    "        \n",
    "        if selected_cluster < n_labels:\n",
    "            if selected_cluster not in ordered_labels:\n",
    "                ordered_labels.append(selected_cluster)\n",
    "            remaining_clusters.remove(selected_cluster)\n",
    "        else:\n",
    "            left, right = linkage[selected_cluster - n_labels, :2].astype(int)\n",
    "            for child in [left, right]:\n",
    "                if child < n_labels and child not in ordered_labels:\n",
    "                    ordered_labels.append(child)\n",
    "            remaining_clusters.remove(selected_cluster)\n",
    "        \n",
    "        # 모든 라벨이 선택되었다면 종료\n",
    "        if len(ordered_labels) == n_labels:\n",
    "            break\n",
    "    \n",
    "    return ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:1\n",
      "/data/nmc/processed_image/combined_images\n",
      "(0,)             148\n",
      "(0, 10)          110\n",
      "(10,)             56\n",
      "(0, 9, 10)        41\n",
      "(0, 9)            41\n",
      "                ... \n",
      "(1, 8, 9, 10)      1\n",
      "(3, 4, 9, 10)      1\n",
      "(5,)               1\n",
      "(1, 2, 9, 10)      1\n",
      "(3, 4)             1\n",
      "Name: label, Length: 65, dtype: int64\n",
      "train size: 686\n",
      "(0,)                30\n",
      "(0, 10)             25\n",
      "(0, 9)              10\n",
      "(0, 9, 10)           8\n",
      "(9, 10)              5\n",
      "(2, 10)              5\n",
      "(1, 2)               4\n",
      "(3, 10)              3\n",
      "(1, 2, 3)            3\n",
      "(1, 2, 3, 8)         3\n",
      "(1, 10)              3\n",
      "(8, 10)              2\n",
      "(2, 8, 10)           2\n",
      "(1, 2, 8, 10)        2\n",
      "(0, 8)               2\n",
      "(1, 2, 8, 9)         2\n",
      "(1, 2, 3, 8, 10)     2\n",
      "(1, 9, 10)           2\n",
      "(0, 8, 10)           1\n",
      "(1, 2, 5, 8)         1\n",
      "(1, 2, 3, 9)         1\n",
      "(1, 2, 9, 10)        1\n",
      "(5, 8, 9, 10)        1\n",
      "(2, 9, 10)           1\n",
      "(2, 4)               1\n",
      "(1, 2, 3, 4)         1\n",
      "(3, 9)               1\n",
      "(1, 4, 9, 10)        1\n",
      "(2, 3, 9)            1\n",
      "(8, 9)               1\n",
      "(2, 4, 9, 10)        1\n",
      "(1, 8, 10)           1\n",
      "(1, 2, 3, 10)        1\n",
      "(3, 4)               1\n",
      "(1, 2, 10)           1\n",
      "(1, 2, 3, 5)         1\n",
      "(10,)                1\n",
      "(1, 2, 8)            1\n",
      "(1, 4)               1\n",
      "Name: label, dtype: int64\n",
      "val size: 134\n",
      "(0,)                34\n",
      "(0, 10)             23\n",
      "(2, 10)             11\n",
      "(0, 9, 10)          10\n",
      "(1, 2)               9\n",
      "(1, 10)              7\n",
      "(0, 9)               7\n",
      "(1, 2, 3)            5\n",
      "(2, 8)               4\n",
      "(8, 10)              4\n",
      "(9,)                 3\n",
      "(9, 10)              3\n",
      "(1, 2, 3, 8)         2\n",
      "(1, 2, 8, 9)         2\n",
      "(2, 3)               2\n",
      "(1, 2, 3, 4)         2\n",
      "(0, 8, 9, 10)        1\n",
      "(1, 2, 3, 8, 10)     1\n",
      "(3, 8, 9, 10)        1\n",
      "(1, 2, 8, 10)        1\n",
      "(1, 9, 10)           1\n",
      "(1, 8)               1\n",
      "(1, 2, 3, 10)        1\n",
      "(3, 8)               1\n",
      "(1, 2, 4, 10)        1\n",
      "(1, 5, 8, 9, 10)     1\n",
      "(4, 9, 10)           1\n",
      "(2, 3, 10)           1\n",
      "(0, 8)               1\n",
      "(1, 3, 10)           1\n",
      "(1, 9)               1\n",
      "(1, 2, 10)           1\n",
      "(4, 10)              1\n",
      "(1, 4)               1\n",
      "(3, 8, 10)           1\n",
      "(3, 9, 10)           1\n",
      "Name: label, dtype: int64\n",
      "test size: 148\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_mf1 = 0.0\n",
    "device = torch.device(cfg['DEVICE'])\n",
    "print(\"device : \",device)\n",
    "num_workers = mp.cpu_count()\n",
    "train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "transformations = get_train_augmentation(train_cfg['IMAGE_SIZE'])\n",
    "batch_size = 32\n",
    "\n",
    "dataset = eval(dataset_cfg['NAME'])(dataset_cfg['ROOT']+'/combined_images',dataset_cfg['TRAIN_RATIO'], dataset_cfg['VALID_RATIO'], dataset_cfg['TEST_RATIO'],  transformations)\n",
    "trainset, valset, testset = dataset.get_splits()\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting labels: 100%|██████████| 21/21 [00:11<00:00,  1.89it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mi_matrix = analyze_trainloader_labels(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(all_preds, all_labels):\n",
    "    # PyTorch 텐서를 CPU로 이동하고 NumPy 배열로 변환\n",
    "    all_preds = all_preds.cpu().numpy()\n",
    "    all_labels = all_labels.cpu().numpy()\n",
    "    \n",
    "    # 예측값을 0 또는 1로 변환 (임계값 0.5 사용)\n",
    "    pred_binary = (all_preds > 0.5).astype(int)\n",
    "    \n",
    "    # 실제 데이터에 존재하는 클래스 인덱스 찾기\n",
    "    active_classes = np.where(np.sum(all_labels, axis=0) > 0)[0]\n",
    "    \n",
    "    # 전체 정확도 계산\n",
    "    accuracy = accuracy_score(all_labels, pred_binary)\n",
    "    \n",
    "    # 각 클래스별 F1 점수, 정밀도, 재현율 계산 (활성 클래스만)\n",
    "    f1_scores = f1_score(all_labels[:, active_classes], pred_binary[:, active_classes], average=None, zero_division=0)\n",
    "    precision_scores = precision_score(all_labels[:, active_classes], pred_binary[:, active_classes], average=None, zero_division=0)\n",
    "    recall_scores = recall_score(all_labels[:, active_classes], pred_binary[:, active_classes], average=None, zero_division=0)\n",
    "    \n",
    "    # Hamming Loss 계산\n",
    "    hamming = hamming_loss(all_labels, pred_binary)\n",
    "    \n",
    "    # 샘플당 정확히 모든 라벨을 맞춘 비율 (Subset Accuracy)\n",
    "    subset_accuracy = (all_labels == pred_binary).all(axis=1).mean()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'hamming_loss': hamming,\n",
    "        'subset_accuracy': subset_accuracy,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'active_classes': active_classes\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print(\"=== Overall Metrics ===\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
    "    print(f\"Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
    "    print(\"\\n=== Class-wise Metrics ===\")\n",
    "    print(\"Class\\t\\tF1 Score\\tPrecision\\tRecall\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, class_idx in enumerate(metrics['active_classes']):\n",
    "        print(f\"Class {class_idx}:\\t{metrics['f1_scores'][i]:.4f}\\t\\t{metrics['precision_scores'][i]:.4f}\\t\\t{metrics['recall_scores'][i]:.4f}\")\n",
    "    \n",
    "    print(\"\\n=###############== Average Metrics (Active Classes) ==###############=\")\n",
    "    print(f\"Macro F1: {np.mean(metrics['f1_scores']):.4f}\")\n",
    "    print(f\"Macro Precision: {np.mean(metrics['precision_scores']):.4f}\")\n",
    "    print(f\"Macro Recall: {np.mean(metrics['recall_scores']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicMultilabelSampler(Sampler):\n",
    "    def __init__(self, labels, num_samples, batch_size, update_interval, alpha=0.7):\n",
    "        self.labels = labels\n",
    "        self.num_samples = num_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.update_interval = update_interval\n",
    "        self.num_classes = labels.shape[1]\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        class_sample_count = np.sum(self.labels, axis=0)\n",
    "        class_weights = np.where(class_sample_count > 0, 1. / class_sample_count, 0.)\n",
    "        self.initial_class_probs = class_weights / np.sum(class_weights)\n",
    "        self.class_probs = self.initial_class_probs.copy()\n",
    "\n",
    "        self.class_losses = np.ones(self.num_classes)\n",
    "\n",
    "    def update_class_probs(self, class_losses):\n",
    "        class_losses_np = class_losses.cpu().numpy()\n",
    "        normalized_losses = class_losses_np / np.sum(class_losses_np)\n",
    "        self.class_probs = (self.alpha * normalized_losses + \n",
    "                            (1 - self.alpha) * self.initial_class_probs)\n",
    "        self.class_probs /= np.sum(self.class_probs)\n",
    "\n",
    "    def update_class_losses(self, class_losses):\n",
    "        self.class_losses = class_losses.cpu().numpy()\n",
    "\n",
    "    def __iter__(self):\n",
    "        num_batches = self.update_interval\n",
    "        all_batches = []\n",
    "\n",
    "        # update_interval 만큼의 배치만 생성\n",
    "        for _ in range(num_batches):\n",
    "            batch = []\n",
    "            for _ in range(self.batch_size):\n",
    "                selected_class = np.random.choice(self.num_classes, p=self.class_probs)\n",
    "                samples_of_class = np.where(self.labels[:, selected_class] == 1)[0]\n",
    "                if len(samples_of_class) > 0:\n",
    "                    selected_sample = np.random.choice(samples_of_class)\n",
    "                    batch.append(selected_sample)\n",
    "                else:\n",
    "                    batch.append(np.random.randint(len(self.labels)))\n",
    "            all_batches.append(batch)\n",
    "\n",
    "        # 배치 간 순서 조정\n",
    "        batch_losses = []\n",
    "        for batch in all_batches:\n",
    "            batch_loss = np.max([np.max(self.class_losses[self.labels[sample] == 1]) for sample in batch])\n",
    "            batch_losses.append(batch_loss)\n",
    "\n",
    "        # 배치를 손실 기준으로 정렬 (손실이 높은 배치가 뒤로)\n",
    "        sorted_batches = [batch for _, batch in sorted(zip(batch_losses, all_batches), key=lambda x: x[0])]\n",
    "\n",
    "        # 정렬된 배치 반환\n",
    "        for batch in sorted_batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.update_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "Epoch: [1/10] Major Iter: [1/3] Iter: [7/7] Loss: 0.3795: 100%|██████████| 7/7 [00:59<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.2703 |        14.0000 | 2.3171 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0435 |       157.0000 | 0.2893 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0459 |       133.0000 | 0.3283 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.0880 |        89.0000 | 0.5961 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.1622 |        44.0000 | 0.8886 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2037 |       132.0000 | 0.3194 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0500 |       137.0000 | 0.2916 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.0899 |        71.0000 | 0.7008 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0465 |       149.0000 | 0.3658 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10] Major Iter: [2/3] Iter: [7/7] Loss: 0.3887: 100%|██████████| 7/7 [00:54<00:00,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.1929 |        78.0000 | 2.2065 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0615 |       107.0000 | 0.5991 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0507 |        92.0000 | 0.4958 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.1167 |        61.0000 | 1.1367 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.1675 |        46.0000 | 1.2563 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2334 |        46.0000 | 0.7766 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0526 |        72.0000 | 0.4223 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.0782 |        81.0000 | 0.8043 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0464 |       132.0000 | 0.4899 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10] Major Iter: [3/3] Iter: [7/7] Loss: 0.3396: 100%|██████████| 7/7 [00:54<00:00,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.1140 |        52.0000 | 1.2411 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0659 |       121.0000 | 0.6287 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0799 |       108.0000 | 0.8099 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.1020 |        88.0000 | 0.9333 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.1921 |        40.0000 | 1.4925 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2544 |        64.0000 | 0.9881 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0821 |        84.0000 | 0.7421 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.0652 |        64.0000 | 0.6303 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0444 |       131.0000 | 0.4513 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n",
      "\n",
      "Epoch 1 completed. Average loss: 0.4300\n",
      "\n",
      "Total class distribution for this epoch:\n",
      "Class 0: 144.0\n",
      "Class 1: 385.0\n",
      "Class 2: 333.0\n",
      "Class 3: 238.0\n",
      "Class 4: 130.0\n",
      "Class 5: 242.0\n",
      "Class 6: 0.0\n",
      "Class 7: 0.0\n",
      "Class 8: 293.0\n",
      "Class 9: 216.0\n",
      "Class 10: 412.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Metrics ===\n",
      "Accuracy: 0.0075\n",
      "Hamming Loss: 0.3643\n",
      "Subset Accuracy: 0.0075\n",
      "\n",
      "=== Class-wise Metrics ===\n",
      "Class\t\tF1 Score\tPrecision\tRecall\n",
      "--------------------------------------------------\n",
      "Class 0:\t0.0000\t\t0.0000\t\t0.0000\n",
      "Class 1:\t0.3804\t\t0.2366\t\t0.9688\n",
      "Class 2:\t0.4426\t\t0.3103\t\t0.7714\n",
      "Class 3:\t0.2885\t\t0.1744\t\t0.8333\n",
      "Class 4:\t0.0526\t\t0.0312\t\t0.1667\n",
      "Class 5:\t0.0952\t\t0.0500\t\t1.0000\n",
      "Class 8:\t0.3947\t\t0.2727\t\t0.7143\n",
      "Class 9:\t0.5538\t\t0.6207\t\t0.5000\n",
      "Class 10:\t0.6479\t\t0.6301\t\t0.6667\n",
      "\n",
      "=###############== Average Metrics (Active Classes) ==###############=\n",
      "Macro F1: 0.3173\n",
      "Macro Precision: 0.2585\n",
      "Macro Recall: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10] Major Iter: [1/3] Iter: [7/7] Loss: 0.3356: 100%|██████████| 7/7 [00:55<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.1221 |        34.0000 | 1.0297 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0591 |       139.0000 | 0.4264 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0600 |       131.0000 | 0.4520 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.0690 |        89.0000 | 0.4324 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.2036 |        56.0000 | 1.2541 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2369 |        58.0000 | 0.6111 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0854 |        90.0000 | 0.6019 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.1121 |        64.0000 | 0.8967 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0518 |       118.0000 | 0.4130 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10] Major Iter: [2/3] Iter: [7/7] Loss: 0.2865: 100%|██████████| 7/7 [00:54<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.1866 |        40.0000 | 1.4925 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0607 |       114.0000 | 0.4123 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0431 |       111.0000 | 0.2848 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.1098 |        64.0000 | 0.7384 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.1331 |        61.0000 | 0.5973 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2410 |        59.0000 | 0.6056 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0546 |        84.0000 | 0.3119 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.0855 |        62.0000 | 0.6223 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0856 |       122.0000 | 0.6629 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10] Major Iter: [3/3] Iter: [7/7] Loss: 0.3243: 100%|██████████| 7/7 [00:53<00:00,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Statistics:\n",
      "+---------+-----------------+----------------+--------+\n",
      "|   Class |   Sampling Prob |   Distribution |   Loss |\n",
      "+=========+=================+================+========+\n",
      "|       0 |          0.1655 |        70.0000 | 1.5631 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       1 |          0.0697 |       111.0000 | 0.5759 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       2 |          0.0567 |        95.0000 | 0.4699 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       3 |          0.1361 |        76.0000 | 1.1301 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       4 |          0.1637 |        34.0000 | 1.0041 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       5 |          0.2204 |        47.0000 | 0.5179 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       8 |          0.0427 |        76.0000 | 0.2537 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|       9 |          0.0911 |        69.0000 | 0.7919 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "|      10 |          0.0542 |       116.0000 | 0.4812 |\n",
      "+---------+-----------------+----------------+--------+\n",
      "\n",
      "\n",
      "Epoch 2 completed. Average loss: 0.3485\n",
      "\n",
      "Total class distribution for this epoch:\n",
      "Class 0: 144.0\n",
      "Class 1: 364.0\n",
      "Class 2: 337.0\n",
      "Class 3: 229.0\n",
      "Class 4: 151.0\n",
      "Class 5: 164.0\n",
      "Class 6: 0.0\n",
      "Class 7: 0.0\n",
      "Class 8: 250.0\n",
      "Class 9: 195.0\n",
      "Class 10: 356.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Metrics ===\n",
      "Accuracy: 0.0373\n",
      "Hamming Loss: 0.2090\n",
      "Subset Accuracy: 0.0373\n",
      "\n",
      "=== Class-wise Metrics ===\n",
      "Class\t\tF1 Score\tPrecision\tRecall\n",
      "--------------------------------------------------\n",
      "Class 0:\t0.0750\t\t0.7500\t\t0.0395\n",
      "Class 1:\t0.4545\t\t0.3571\t\t0.6250\n",
      "Class 2:\t0.6667\t\t0.8000\t\t0.5714\n",
      "Class 3:\t0.3636\t\t0.4000\t\t0.3333\n",
      "Class 4:\t0.0000\t\t0.0000\t\t0.0000\n",
      "Class 5:\t0.1905\t\t0.1111\t\t0.6667\n",
      "Class 8:\t0.5263\t\t0.4167\t\t0.7143\n",
      "Class 9:\t0.4615\t\t0.5172\t\t0.4167\n",
      "Class 10:\t0.6111\t\t0.5867\t\t0.6377\n",
      "\n",
      "=###############== Average Metrics (Active Classes) ==###############=\n",
      "Macro F1: 0.3721\n",
      "Macro Precision: 0.4376\n",
      "Macro Recall: 0.4449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10] Major Iter: [1/3]:   0%|          | 0/7 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1494537/3939880890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     desc=f\"Epoch: [{epoch+1}/{epochs}] Major Iter: [{major_iter+1}/{iterations_per_epoch}]\")\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/gmpark/nmc_2024/nmc/datasets/NMC.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/gmpark/nmc_2024/nmc/augmentations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/gmpark/nmc_2024/nmc/augmentations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# 이미지 리사이즈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpolationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# 패딩 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, antialias)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0malign_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bicubic\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bicubic\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gm/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsample_bilinear2d_aa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, dataset.n_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "criterion_bce_cls = nn.BCEWithLogitsLoss(reduction='none')\n",
    "scaler = GradScaler(enabled=train_cfg['AMP'])\n",
    "\n",
    "train_labels = dataset.train_data[1]  # 원-핫 인코딩된 레이블\n",
    "\n",
    "epochs = 10\n",
    "update_interval = 7\n",
    "total_iterations = len(train_labels) // batch_size\n",
    "iterations_per_epoch = total_iterations // update_interval\n",
    "\n",
    "sampler = DynamicMultilabelSampler(train_labels, len(train_labels), batch_size, update_interval)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    resnet.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    total_class_counts = torch.zeros(dataset.n_classes, device=device)\n",
    "    \n",
    "    # 에포크 시작 시 이전 에포크의 avg_class_losses 사용 (첫 에포크에는 None)\n",
    "    prev_avg_class_losses = None\n",
    "    \n",
    "    for major_iter in range(iterations_per_epoch):\n",
    "        if prev_avg_class_losses is not None:\n",
    "            sampler.update_class_losses(prev_avg_class_losses)\n",
    "        \n",
    "        class_losses = torch.zeros(dataset.n_classes, device=device)\n",
    "        class_counts = torch.zeros(dataset.n_classes, device=device)\n",
    "        \n",
    "        trainloader = DataLoader(trainset, batch_sampler=sampler, num_workers=0)\n",
    "        pbar = tqdm(enumerate(trainloader), total=update_interval, \n",
    "                    desc=f\"Epoch: [{epoch+1}/{epochs}] Major Iter: [{major_iter+1}/{iterations_per_epoch}]\")\n",
    "        \n",
    "        for iter, (img, lbl) in pbar:\n",
    "            img = img.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            batch_class_counts = torch.sum(lbl, dim=0)\n",
    "            total_class_counts += batch_class_counts\n",
    "            class_counts += batch_class_counts\n",
    "            \n",
    "            with autocast(enabled=train_cfg['AMP']):\n",
    "                logits = resnet(img)\n",
    "                loss_per_sample = criterion_bce_cls(logits, lbl)\n",
    "                loss_per_class = torch.sum(loss_per_sample * lbl, dim=0)\n",
    "                class_losses += loss_per_class\n",
    "                loss = loss_per_sample.mean()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pbar.set_description(f\"Epoch: [{epoch+1}/{epochs}] Major Iter: [{major_iter+1}/{iterations_per_epoch}] \"\n",
    "                                 f\"Iter: [{iter+1}/{update_interval}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # update_interval 후 샘플링 확률 업데이트\n",
    "        avg_class_losses = (class_losses / class_counts.clamp(min=1)).detach()\n",
    "        prev_avg_class_losses = avg_class_losses  # 다음 major iteration을 위해 저장\n",
    "        sampler.update_class_probs(avg_class_losses)\n",
    "\n",
    "        # 클래스 통계 출력\n",
    "        table_data = []\n",
    "        for i in range(dataset.n_classes):\n",
    "            if class_counts[i] > 0:\n",
    "                distribution = class_counts[i].item()\n",
    "                loss = avg_class_losses[i].item()\n",
    "                sampling_prob = sampler.class_probs[i]\n",
    "                table_data.append([i, f\"{sampling_prob:.4f}\", distribution, f\"{loss:.4f}\"])\n",
    "        \n",
    "        table = tabulate(table_data, \n",
    "                         headers=[\"Class\",\"Sampling Prob\", \"Distribution\", \"Loss\"],\n",
    "                         tablefmt=\"grid\", \n",
    "                         floatfmt=\".4f\")\n",
    "        \n",
    "        print(f\"\\nClass Statistics:\")\n",
    "        print(table)\n",
    "        print()  # 빈 줄 추가\n",
    "\n",
    "    train_loss /= (iterations_per_epoch * update_interval)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} completed. Average loss: {train_loss:.4f}\")\n",
    "    print(\"\\nTotal class distribution for this epoch:\")\n",
    "    for i, count in enumerate(total_class_counts.cpu().numpy()):\n",
    "        print(f\"Class {i}: {count}\")\n",
    "\n",
    "    # 평가 부분\n",
    "    resnet.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for img, lbl in valloader:\n",
    "            img = img.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            logits = resnet(img)    \n",
    "            all_preds.append(logits)\n",
    "            all_labels.append(lbl)\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    metrics = calculate_metrics(all_preds, all_labels)\n",
    "    print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Metrics ===\n",
      "Accuracy: 0.1014\n",
      "Hamming Loss: 0.1462\n",
      "Subset Accuracy: 0.1014\n",
      "\n",
      "=== Class-wise Metrics ===\n",
      "Class\t\tF1 Score\tPrecision\tRecall\n",
      "--------------------------------------------------\n",
      "Class 0:\t0.3011\t\t0.8235\t\t0.1842\n",
      "Class 1:\t0.5974\t\t0.5897\t\t0.6053\n",
      "Class 2:\t0.7097\t\t0.6600\t\t0.7674\n",
      "Class 3:\t0.4571\t\t0.5000\t\t0.4211\n",
      "Class 4:\t0.0000\t\t0.0000\t\t0.0000\n",
      "Class 5:\t0.0000\t\t0.0000\t\t0.0000\n",
      "Class 8:\t0.6809\t\t0.6154\t\t0.7619\n",
      "Class 9:\t0.6667\t\t0.5814\t\t0.7812\n",
      "Class 10:\t0.6333\t\t0.8085\t\t0.5205\n",
      "\n",
      "=== Average Metrics (Active Classes) ===\n",
      "Macro F1: 0.4496\n",
      "Macro Precision: 0.5087\n",
      "Macro Recall: 0.4491\n"
     ]
    }
   ],
   "source": [
    "# 평가 부분은 그대로 유지\n",
    "resnet.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for img, lbl in testloader:\n",
    "        img = img.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        logits = resnet(img)    \n",
    "        score = calculate_metrics(logits, lbl)\n",
    "        all_preds.append(logits)\n",
    "        all_labels.append(lbl)\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "metrics = calculate_metrics(all_preds, all_labels)\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 러닝레이트확인\n",
    "\n",
    "# 순서변경, 난이도에 따른 샘플 선택 도입\n",
    "\n",
    "# 난이도 확인 후 augmentation으로 공헌?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
