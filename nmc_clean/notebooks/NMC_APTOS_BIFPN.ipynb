{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from torch import distributed as dist\n",
    "from nmc.models import *\n",
    "from nmc.datasets import * \n",
    "from nmc.augmentations import get_train_augmentation, get_val_augmentation\n",
    "from nmc.losses import get_loss\n",
    "from nmc.schedulers import get_scheduler\n",
    "from nmc.optimizers import get_optimizer\n",
    "from nmc.utils.utils import fix_seeds, setup_cudnn, cleanup_ddp, setup_ddp\n",
    "from tools.val import evaluate_epi\n",
    "from nmc.utils.episodic_utils import * \n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda:0', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'EfficientNetV2MModel', 'BACKBONE': 'EfficientNetV2', 'PRETRAINED': '/workspace/jhmoon/nmc_2024/checkpoints/pretrained/tf_efficientnetv2_m_weights.pth', 'UNFREEZE': 'full', 'VERSION': '384_32'}, 'DATASET': {'NAME': 'APTOSDataset', 'ROOT': '/data/public_data/aptos', 'TRAIN_RATIO': 0.7, 'VALID_RATIO': 0.15, 'TEST_RATIO': 0.15}, 'TRAIN': {'IMAGE_SIZE': [384, 384], 'BATCH_SIZE': 32, 'EPOCHS': 100, 'EVAL_INTERVAL': 25, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'CrossEntropy', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 0.001, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.APTOS.pth', 'IMAGE_SIZE': [384, 384]}, 'TEST': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.APTOS.pth', 'FILE': 'assests/ade', 'IMAGE_SIZE': [384, 384], 'OVERLAY': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('../configs/APTOS.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "print(cfg)\n",
    "fix_seeds(3407)\n",
    "setup_cudnn()\n",
    "gpu = setup_ddp()\n",
    "save_dir = Path(cfg['SAVE_DIR'])\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augmentation(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_test_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # 데이터셋에서 레이블 추출\n",
    "        if hasattr(dataset, 'labels'):\n",
    "            self.labels = dataset.labels\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        elif hasattr(dataset, 'targets'):\n",
    "            self.labels = dataset.targets\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        else:\n",
    "            try:\n",
    "                self.labels = [sample[1] for sample in dataset]\n",
    "                if isinstance(self.labels[0], np.ndarray):\n",
    "                    self.labels = torch.from_numpy(np.array(self.labels))\n",
    "                else:\n",
    "                    self.labels = torch.tensor(self.labels)\n",
    "            except:\n",
    "                raise ValueError(\"Cannot access labels from dataset\")\n",
    "        \n",
    "        self.n_classes = self.labels.shape[1] if len(self.labels.shape) > 1 else len(torch.unique(self.labels))\n",
    "        self.samples_per_class = batch_size // self.n_classes\n",
    "        \n",
    "        # 클래스별 인덱스 저장\n",
    "        self.class_indices = []\n",
    "        for i in range(self.n_classes):\n",
    "            if len(self.labels.shape) > 1:\n",
    "                idx = torch.where(self.labels[:, i] == 1)[0]\n",
    "            else:\n",
    "                idx = torch.where(self.labels == i)[0]\n",
    "            self.class_indices.append(idx)\n",
    "        \n",
    "        self.n_batches = len(self.dataset) // batch_size\n",
    "        if len(self.dataset) % batch_size != 0:\n",
    "            self.n_batches += 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for _ in range(self.n_batches):\n",
    "            batch_indices = []\n",
    "            for class_idx in range(self.n_classes):\n",
    "                class_samples = self.class_indices[class_idx]\n",
    "                if len(class_samples) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # 랜덤 선택\n",
    "                selected = class_samples[torch.randint(len(class_samples), \n",
    "                                                     (self.samples_per_class,))]\n",
    "                batch_indices.extend(selected.tolist())\n",
    "            \n",
    "            # 배치 크기에 맞게 자르기\n",
    "            if len(batch_indices) > self.batch_size:\n",
    "                batch_indices = batch_indices[:self.batch_size]\n",
    "            \n",
    "            # 중요: 리스트로 yield\n",
    "            yield batch_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:0\n",
      "/data/public_data/aptos/combined_images\n",
      "0    1263\n",
      "2     699\n",
      "1     259\n",
      "4     207\n",
      "3     135\n",
      "Name: diagnosis, dtype: int64\n",
      "Train size: 2563\n",
      "0    271\n",
      "2    150\n",
      "1     55\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Validation size: 549\n",
      "0    271\n",
      "2    150\n",
      "1     56\n",
      "4     44\n",
      "3     29\n",
      "Name: diagnosis, dtype: int64\n",
      "Test size: 550\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_mf1 = 0.0\n",
    "device = torch.device(cfg['DEVICE'])\n",
    "print(\"device : \", device)\n",
    "num_workers = mp.cpu_count()\n",
    "train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "image_size = [256,256]\n",
    "image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "train_transform = get_train_augmentation(image_size)\n",
    "val_test_transform = get_val_test_transform(image_size)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataset = eval(dataset_cfg['NAME'])(\n",
    "    dataset_cfg['ROOT'] + '/combined_images',\n",
    "    dataset_cfg['TRAIN_RATIO'],\n",
    "    dataset_cfg['VALID_RATIO'],\n",
    "    dataset_cfg['TEST_RATIO'],\n",
    "    transform=None\n",
    ")\n",
    "trainset, valset, testset = dataset.get_splits()\n",
    "trainset.transform = train_transform\n",
    "valset.transform = val_test_transform\n",
    "testset.transform = val_test_transform\n",
    "\n",
    "# DataLoader 수정\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_sampler=BalancedBatchSampler(trainset, batch_size=batch_size),\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedFeatureFusion(nn.Module):\n",
    "    def __init__(self, num_inputs):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.ones(num_inputs, dtype=torch.float32), requires_grad=True)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # weights를 softmax로 정규화\n",
    "        normalized_weights = F.softmax(self.weights, dim=0)\n",
    "        # 가중치를 적용하고 합산\n",
    "        weighted_sum = sum(w * f for w, f in zip(normalized_weights, features))\n",
    "        return weighted_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiFPNBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Top-down 경로의 가중치 합산 layers\n",
    "        self.td_weights = nn.ModuleList([\n",
    "            WeightedFeatureFusion(2) for _ in range(4)  # P6->P3까지 4개의 fusion\n",
    "        ])\n",
    "        \n",
    "        # Bottom-up 경로의 가중치 합산 layers\n",
    "        self.bu_weights = nn.ModuleList([\n",
    "            WeightedFeatureFusion(3) for _ in range(3)  # P4->P6까지 3개의 fusion\n",
    "        ])\n",
    "        self.bu_weights.append(WeightedFeatureFusion(2))  # P7은 2개 input\n",
    "        \n",
    "        # Convolution layers 수정\n",
    "        self.conv_td = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                # Depthwise convolution의 groups를 channels로 설정\n",
    "                nn.Conv2d(channels, channels, 3, padding=1, groups=channels),\n",
    "                # Pointwise convolution으로 채널 간 정보 교환\n",
    "                nn.Conv2d(channels, channels, 1),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(5)  # P7->P3\n",
    "        ])\n",
    "        \n",
    "        self.conv_bu = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels, channels, 3, padding=1, groups=channels),\n",
    "                nn.Conv2d(channels, channels, 1),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(5)  # P3->P7\n",
    "        ])\n",
    "        \n",
    "    def _resize_features(self, source, target):\n",
    "        target_size = target.shape[-2:]\n",
    "        return F.interpolate(source, size=target_size, mode='nearest')\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # features는 P3->P7 순서로 정렬된 리스트\n",
    "        P3_in, P4_in, P5_in, P6_in, P7_in = features\n",
    "        \n",
    "        # Top-down 경로\n",
    "        P7_td = self.conv_td[0](P7_in)\n",
    "        \n",
    "        P6_td_inputs = [P6_in, self._resize_features(P7_td, P6_in)]\n",
    "        P6_td = self.conv_td[1](self.td_weights[0](P6_td_inputs))\n",
    "        \n",
    "        P5_td_inputs = [P5_in, self._resize_features(P6_td, P5_in)]\n",
    "        P5_td = self.conv_td[2](self.td_weights[1](P5_td_inputs))\n",
    "        \n",
    "        P4_td_inputs = [P4_in, self._resize_features(P5_td, P4_in)]\n",
    "        P4_td = self.conv_td[3](self.td_weights[2](P4_td_inputs))\n",
    "        \n",
    "        P3_td_inputs = [P3_in, self._resize_features(P4_td, P3_in)]\n",
    "        P3_out = self.conv_td[4](self.td_weights[3](P3_td_inputs))\n",
    "        \n",
    "        # Bottom-up 경로\n",
    "        P3_bu = P3_out\n",
    "        \n",
    "        P4_bu_inputs = [P4_in, P4_td, self._resize_features(P3_bu, P4_in)]\n",
    "        P4_out = self.conv_bu[0](self.bu_weights[0](P4_bu_inputs))\n",
    "        \n",
    "        P5_bu_inputs = [P5_in, P5_td, self._resize_features(P4_out, P5_in)]\n",
    "        P5_out = self.conv_bu[1](self.bu_weights[1](P5_bu_inputs))\n",
    "        \n",
    "        P6_bu_inputs = [P6_in, P6_td, self._resize_features(P5_out, P6_in)]\n",
    "        P6_out = self.conv_bu[2](self.bu_weights[2](P6_bu_inputs))\n",
    "        \n",
    "        P7_bu_inputs = [P7_in, self._resize_features(P6_out, P7_in)]\n",
    "        P7_out = self.conv_bu[3](self.bu_weights[3](P7_bu_inputs))\n",
    "        \n",
    "        return [P3_out, P4_out, P5_out, P6_out, P7_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualEfficientNetBiFPN(nn.Module):\n",
    "    def __init__(self, efficientnet_nmc, efficientnet_aptos, num_classes=5, num_bifpn_blocks=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # EfficientNet 모델들 저장 및 freeze\n",
    "        self.nmc_model = efficientnet_nmc\n",
    "        self.aptos_model = efficientnet_aptos\n",
    "        \n",
    "        # Freeze EfficientNet models\n",
    "        for param in self.nmc_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.aptos_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # 주요 블록들의 출력 채널 수 확인\n",
    "        main_blocks = self.get_main_blocks(efficientnet_nmc)\n",
    "        \n",
    "        def find_out_channels(block):\n",
    "            modules = list(block.modules())\n",
    "            for module in reversed(modules):\n",
    "                if isinstance(module, nn.Conv2d):\n",
    "                    return module.out_channels\n",
    "            return None\n",
    "\n",
    "        # 각 블록의 채널 수 저장\n",
    "        self.block_channels = [find_out_channels(block) for block in main_blocks]\n",
    "        print(\"Original block channels:\", self.block_channels)\n",
    "        \n",
    "        # BiFPN에서 사용할 채널 수 (모든 레벨에서 동일하게 사용)\n",
    "        self.bifpn_channels = 160  # 적절한 채널 수로 설정\n",
    "        \n",
    "        # Feature fusion layers\n",
    "        self.fusion_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels * 2, self.bifpn_channels, 1),\n",
    "                nn.BatchNorm2d(self.bifpn_channels),\n",
    "                nn.ReLU()\n",
    "            ) for in_channels in self.block_channels\n",
    "        ])\n",
    "        \n",
    "        # BiFPN blocks\n",
    "        self.bifpn_blocks = nn.ModuleList([\n",
    "            BiFPNBlock(self.bifpn_channels) for _ in range(num_bifpn_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(self.bifpn_channels * 5),\n",
    "            nn.Linear(self.bifpn_channels * 5, num_classes)\n",
    "        )\n",
    "\n",
    "        # Print parameter counts\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params}\")\n",
    "        print(f\"Trainable parameters: {trainable_params}\")\n",
    "        print(f\"Frozen parameters: {total_params - trainable_params}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_main_blocks(model):\n",
    "        return [\n",
    "            model.features[i] for i in range(1, 6)  # P3-P7에 해당하는 5개 레벨\n",
    "        ]\n",
    "    \n",
    "    def extract_features(self, x, model):\n",
    "        features = []\n",
    "        # 먼저 초기 conv layer 통과\n",
    "        x = model.features[0](x)\n",
    "        \n",
    "        # 각 블록을 통과하면서 feature 추출\n",
    "        for block in self.get_main_blocks(model):\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "        return features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 각 모델에서 feature 추출\n",
    "        nmc_features = self.extract_features(x, self.nmc_model)\n",
    "        aptos_features = self.extract_features(x, self.aptos_model)\n",
    "        \n",
    "        # 각 레벨에서 feature concat 후 fusion\n",
    "        combined_features = []\n",
    "        for nmc_feat, aptos_feat, fusion_layer in zip(nmc_features, aptos_features, self.fusion_layers):\n",
    "            # Concatenate features along channel dimension\n",
    "            concat_feat = torch.cat([nmc_feat, aptos_feat], dim=1)\n",
    "            # Apply fusion conv to adjust channels and combine features\n",
    "            fused_feat = fusion_layer(concat_feat)\n",
    "            combined_features.append(fused_feat)\n",
    "        \n",
    "        # BiFPN blocks 통과\n",
    "        bifpn_features = combined_features\n",
    "        for bifpn in self.bifpn_blocks:\n",
    "            bifpn_features = bifpn(bifpn_features)\n",
    "        \n",
    "        # 모든 레벨의 feature를 결합하여 분류\n",
    "        multi_scale_features = torch.cat([self.classifier[0](feat) for feat in bifpn_features], dim=1)\n",
    "        out = self.classifier[1](multi_scale_features)  # Flatten\n",
    "        out = self.classifier[2](out)  # BatchNorm\n",
    "        out = self.classifier[3](out)  # Linear\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=scaler is not None):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "        \n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            # 각 클래스에 대해 시그모이드 적용 후 임계값 처리\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            \n",
    "            # 배치 단위로 예측값과 라벨 저장\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # 배치 데이터를 하나의 배열로 결합\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # 멀티라벨 F1 score 계산\n",
    "    f1 = f1_score(all_labels, all_preds, average='samples')  # or 'micro', 'macro', 'weighted'\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scaler, device, epochs):\n",
    "    best_f1 = 0.0\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_f1)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'model/fusion/best_model_combined_bifpn.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        early_stopping(val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/anaconda3/envs/gm/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Model definition (changed to binary classification)\n",
    "efficientnet_nmc = models.efficientnet_v2_m(pretrained=True)\n",
    "num_ftrs = efficientnet_nmc.classifier[1].in_features\n",
    "efficientnet_nmc.classifier = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.Linear(num_ftrs, 7)\n",
    ")\n",
    "efficientnet_nmc = efficientnet_nmc.to(device)\n",
    "\n",
    "# Model definition (changed to binary classification)\n",
    "efficientnet_aptos = models.efficientnet_v2_m(pretrained=True)\n",
    "num_ftrs = efficientnet_aptos.classifier[1].in_features\n",
    "efficientnet_aptos.classifier = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.Linear(num_ftrs, 5)\n",
    ")\n",
    "efficientnet_aptos = efficientnet_aptos.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original block channels: [24, 48, 80, 160, 176]\n",
      "Total parameters: 106178188\n",
      "Trainable parameters: 440984\n",
      "Frozen parameters: 105737204\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:37<00:00,  2.14it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:29<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5801\n",
      "Validation F1 Score: 0.6435\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:42<00:00,  1.90it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:45<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4993\n",
      "Validation F1 Score: 0.7489\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:34<00:00,  2.32it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4540\n",
      "Validation F1 Score: 0.7069\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:44<00:00,  1.84it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:47<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4099\n",
      "Validation F1 Score: 0.7863\n",
      "New best model saved!\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:42<00:00,  1.89it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:49<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3609\n",
      "Validation F1 Score: 0.8012\n",
      "New best model saved!\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:41<00:00,  1.95it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:50<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3219\n",
      "Validation F1 Score: 0.7902\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:41<00:00,  1.94it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2800\n",
      "Validation F1 Score: 0.8051\n",
      "New best model saved!\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:41<00:00,  1.94it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:47<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2507\n",
      "Validation F1 Score: 0.8069\n",
      "New best model saved!\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:44<00:00,  1.82it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:53<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2143\n",
      "Validation F1 Score: 0.7583\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:41<00:00,  1.97it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:46<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1914\n",
      "Validation F1 Score: 0.7845\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:42<00:00,  1.89it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:57<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1683\n",
      "Validation F1 Score: 0.7140\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:42<00:00,  1.89it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1493\n",
      "Validation F1 Score: 0.7073\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:42<00:00,  1.89it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:46<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1395\n",
      "Validation F1 Score: 0.7013\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:43<00:00,  1.87it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1223\n",
      "Validation F1 Score: 0.7116\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:43<00:00,  1.85it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:40<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1148\n",
      "Validation F1 Score: 0.8087\n",
      "New best model saved!\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:39<00:00,  2.07it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:36<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1152\n",
      "Validation F1 Score: 0.7966\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.11it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:40<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1098\n",
      "Validation F1 Score: 0.8069\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.10it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:47<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1096\n",
      "Validation F1 Score: 0.8124\n",
      "New best model saved!\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.08it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:44<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1052\n",
      "Validation F1 Score: 0.7905\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:39<00:00,  2.04it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:48<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1081\n",
      "Validation F1 Score: 0.8009\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:35<00:00,  2.27it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0998\n",
      "Validation F1 Score: 0.7966\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.11it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0982\n",
      "Validation F1 Score: 0.8002\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.09it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1009\n",
      "Validation F1 Score: 0.8045\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:39<00:00,  2.07it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:43<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1014\n",
      "Validation F1 Score: 0.7954\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.12it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:50<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0970\n",
      "Validation F1 Score: 0.8160\n",
      "New best model saved!\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:37<00:00,  2.13it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:40<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1013\n",
      "Validation F1 Score: 0.8112\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.13it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0966\n",
      "Validation F1 Score: 0.8063\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:37<00:00,  2.15it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:48<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0971\n",
      "Validation F1 Score: 0.8015\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:36<00:00,  2.19it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0944\n",
      "Validation F1 Score: 0.8021\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.12it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:46<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1001\n",
      "Validation F1 Score: 0.8009\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.08it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0964\n",
      "Validation F1 Score: 0.8081\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-07.\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:36<00:00,  2.19it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0952\n",
      "Validation F1 Score: 0.8106\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.12it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:38<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0989\n",
      "Validation F1 Score: 0.8130\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:37<00:00,  2.16it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:44<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0986\n",
      "Validation F1 Score: 0.8094\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [00:38<00:00,  2.11it/s]\n",
      "Evaluating: 100%|██████████| 549/549 [01:42<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1044\n",
      "Validation F1 Score: 0.8075\n",
      "Early stopping triggered\n",
      "Training completed. Best F1 Score: 0.8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "# 정규화, lr스케쥴링, 데이터 증강, 조기종료, 배치정규화\n",
    "epochs = 100\n",
    "\n",
    "efficientnet_nmc.load_state_dict(torch.load('model/multilabel/best_model_nmc_cnn.pth'))\n",
    "efficientnet_aptos.load_state_dict(torch.load('model/multilabel/best_model_aptos_cnn.pth'))\n",
    "\n",
    "# 모델 생성\n",
    "combined_model = DualEfficientNetBiFPN(\n",
    "    efficientnet_nmc=efficientnet_nmc,\n",
    "    efficientnet_aptos=efficientnet_aptos,\n",
    "    num_classes=5,  # APTOS의 클래스 수에 맞춤\n",
    "    num_bifpn_blocks=1\n",
    ").to(device)\n",
    "\n",
    "# L2 regularization\n",
    "weight_decay = 1e-4\n",
    "# Optimizer 생성 시 학습 가능한 파라미터만 전달\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, combined_model.parameters()),\n",
    "    lr=0.0001, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scaler = GradScaler(enabled=train_cfg['AMP'])\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "\n",
    "best_f1 = train_and_evaluate(combined_model, trainloader, valloader, criterion, optimizer, scaler, device, epochs)\n",
    "\n",
    "print(f\"Training completed. Best F1 Score: {best_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original block channels: [24, 48, 80, 160, 176]\n",
      "Total parameters: 106178188\n",
      "Trainable parameters: 440984\n",
      "Frozen parameters: 105737204\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "combined_model = DualEfficientNetBiFPN(\n",
    "    efficientnet_nmc=efficientnet_nmc,\n",
    "    efficientnet_aptos=efficientnet_aptos,\n",
    "    num_classes=5,  # APTOS의 클래스 수에 맞춤\n",
    "    num_bifpn_blocks=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:27<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "combined_model.load_state_dict(torch.load('model/fusion/best_model_combined_bifpn.pth'))\n",
    "test_f1 = evaluate(combined_model, testloader, device)\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            # 각 클래스에 대해 시그모이드 적용 후 임계값 처리\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            \n",
    "            # 배치 단위로 예측값과 라벨 저장\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # 배치 데이터를 하나의 배열로 결합\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # 전체 F1 score 계산\n",
    "    overall_f1 = f1_score(all_labels, all_preds, average='samples')\n",
    "    \n",
    "    # 각 클래스별 F1 score 계산\n",
    "    class_f1_scores = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    # 각 클래스별 정밀도(Precision)와 재현율(Recall) 계산\n",
    "    class_precision = precision_score(all_labels, all_preds, average=None)\n",
    "    class_recall = recall_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    # 결과를 딕셔너리로 정리\n",
    "    results = {\n",
    "        'overall_f1': overall_f1,\n",
    "        'class_f1_scores': class_f1_scores,\n",
    "        'class_precision': class_precision,\n",
    "        'class_recall': class_recall\n",
    "    }\n",
    "    \n",
    "    # 각 클래스별 메트릭 출력\n",
    "    print(\"\\nPer-class Performance Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}:\")\n",
    "        print(f\"  F1-Score: {class_f1_scores[i]:.4f}\")\n",
    "        print(f\"  Precision: {class_precision[i]:.4f}\")\n",
    "        print(f\"  Recall: {class_recall[i]:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 550/550 [01:23<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-class Performance Metrics:\n",
      "--------------------------------------------------\n",
      "Class 0:\n",
      "  F1-Score: 0.9778\n",
      "  Precision: 0.9814\n",
      "  Recall: 0.9742\n",
      "Class 1:\n",
      "  F1-Score: 0.5937\n",
      "  Precision: 0.5278\n",
      "  Recall: 0.6786\n",
      "Class 2:\n",
      "  F1-Score: 0.7586\n",
      "  Precision: 0.7160\n",
      "  Recall: 0.8067\n",
      "Class 3:\n",
      "  F1-Score: 0.3793\n",
      "  Precision: 0.3793\n",
      "  Recall: 0.3793\n",
      "Class 4:\n",
      "  F1-Score: 0.6429\n",
      "  Precision: 0.6750\n",
      "  Recall: 0.6136\n",
      "--------------------------------------------------\n",
      "Overall F1-Score: 0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "combined_model.load_state_dict(torch.load('model/fusion/best_model_combined_bifpn.pth'))\n",
    "test_f1 = evaluate(combined_model, testloader, device,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
