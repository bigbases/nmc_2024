{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 싱글모델로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from torch import distributed as dist\n",
    "from nmc.models import *\n",
    "from nmc.datasets import * \n",
    "from nmc.augmentations import get_train_augmentation, get_val_augmentation\n",
    "from nmc.losses import get_loss\n",
    "from nmc.schedulers import get_scheduler\n",
    "from nmc.optimizers import get_optimizer\n",
    "from nmc.utils.utils import fix_seeds, setup_cudnn, cleanup_ddp, setup_ddp\n",
    "from tools.val import evaluate_epi\n",
    "from nmc.utils.episodic_utils import * \n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda:0', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'EfficientNetV2MModelMulti', 'BACKBONE': 'EfficientNetV2', 'PRETRAINED': '/workspace/jhmoon/nmc_2024/checkpoints/pretrained/tf_efficientnetv2_m_weights.pth', 'UNFREEZE': 'full', 'VERSION': \"384_32_loss'\"}, 'DATASET': {'NAME': 'NMCDataset', 'ROOT': '/data/nmc/processed_image', 'TRAIN_RATIO': 0.7, 'VALID_RATIO': 0.15, 'TEST_RATIO': 0.15}, 'TRAIN': {'IMAGE_SIZE': [384, 384], 'BATCH_SIZE': 32, 'EPOCHS': 100, 'EVAL_INTERVAL': 1, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'BCEWithLogitsLoss', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 0.1, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'IMAGE_SIZE': [384, 384]}, 'TEST': {'MODEL_PATH': 'checkpoints/pretrained/FGMaxxVit/FGMaxxVit.FGMaxxVit.NMC.pth', 'FILE': 'assests/ade', 'IMAGE_SIZE': [384, 384], 'OVERLAY': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('../configs/NMC.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "print(cfg)\n",
    "fix_seeds(3407)\n",
    "setup_cudnn()\n",
    "gpu = setup_ddp()\n",
    "save_dir = Path(cfg['SAVE_DIR'])\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augmentation(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_test_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.Lambda(lambda x: x.float() if x.dtype == torch.uint8 else x),\n",
    "        transforms.Lambda(lambda x: x / 255.0 if x.max() > 1.0 else x),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTargetBalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, target_classes):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.target_classes = target_classes\n",
    "        \n",
    "        # 데이터셋에서 레이블 추출\n",
    "        if hasattr(dataset, 'labels'):\n",
    "            self.labels = dataset.labels\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        elif hasattr(dataset, 'targets'):\n",
    "            self.labels = dataset.targets\n",
    "            if isinstance(self.labels, np.ndarray):\n",
    "                self.labels = torch.from_numpy(self.labels)\n",
    "        else:\n",
    "            try:\n",
    "                self.labels = [sample[1] for sample in dataset]\n",
    "                if isinstance(self.labels[0], np.ndarray):\n",
    "                    self.labels = torch.from_numpy(np.array(self.labels))\n",
    "                else:\n",
    "                    self.labels = torch.tensor(self.labels)\n",
    "            except:\n",
    "                raise ValueError(\"Cannot access labels from dataset\")\n",
    "        \n",
    "        # 각 타겟 클래스와 나머지 클래스의 인덱스 저장\n",
    "        self.target_indices = {}\n",
    "        for target in target_classes:\n",
    "            if len(self.labels.shape) > 1:\n",
    "                self.target_indices[target] = torch.where(self.labels[:, target] == 1)[0]\n",
    "            else:\n",
    "                self.target_indices[target] = torch.where(self.labels == target)[0]\n",
    "        \n",
    "        # 나머지 클래스의 인덱스 저장\n",
    "        if len(self.labels.shape) > 1:\n",
    "            self.other_indices = torch.where(\n",
    "                torch.sum(self.labels[:, target_classes], dim=1) == 0)[0]\n",
    "        else:\n",
    "            mask = torch.ones_like(self.labels, dtype=torch.bool)\n",
    "            for target in target_classes:\n",
    "                mask &= (self.labels != target)\n",
    "            self.other_indices = torch.where(mask)[0]\n",
    "        \n",
    "        # 각 그룹당 샘플 수 계산\n",
    "        n_groups = len(target_classes) + 1  # 타겟 클래스들 + 나머지\n",
    "        self.samples_per_group = batch_size // n_groups\n",
    "        \n",
    "        self.n_batches = len(self.dataset) // batch_size\n",
    "        if len(self.dataset) % batch_size != 0:\n",
    "            self.n_batches += 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for _ in range(self.n_batches):\n",
    "            batch_indices = []\n",
    "            \n",
    "            # 각 타겟 클래스에서 샘플링\n",
    "            for target in self.target_classes:\n",
    "                target_selected = self.target_indices[target][\n",
    "                    torch.randint(len(self.target_indices[target]), \n",
    "                                (self.samples_per_group,))\n",
    "                ]\n",
    "                batch_indices.extend(target_selected.tolist())\n",
    "            \n",
    "            # 나머지 클래스들에서 샘플링\n",
    "            other_selected = self.other_indices[\n",
    "                torch.randint(len(self.other_indices), \n",
    "                            (self.samples_per_group,))\n",
    "            ]\n",
    "            batch_indices.extend(other_selected.tolist())\n",
    "            \n",
    "            # 배치 셔플\n",
    "            random.shuffle(batch_indices)\n",
    "            \n",
    "            # 배치 크기에 맞게 자르기 (나누어 떨어지지 않는 경우 처리)\n",
    "            if len(batch_indices) > self.batch_size:\n",
    "                batch_indices = batch_indices[:self.batch_size]\n",
    "            \n",
    "            yield batch_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device, target_label_idx):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_targets = len(target_label_idx)\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        if num_targets == 1:\n",
    "            # 단일 레이블 케이스\n",
    "            target_labels = labels[:, target_label_idx].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                # 차원을 맞춰줌\n",
    "                outputs = outputs.view(-1)  # or outputs.squeeze()\n",
    "                target_labels = target_labels.view(-1)  # or target_labels.squeeze()\n",
    "                loss = criterion(outputs, target_labels)\n",
    "        else:\n",
    "            # 다중 레이블 케이스\n",
    "            target_labels = labels[:, target_label_idx].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, target_labels)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, target_label_idx):\n",
    "   model.eval()\n",
    "   all_preds = []\n",
    "   all_labels = []\n",
    "   num_targets = len(target_label_idx)\n",
    "   \n",
    "   with torch.no_grad():\n",
    "       for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "           images = images.to(device)\n",
    "           \n",
    "           if num_targets == 1:\n",
    "               # 단일 레이블 케이스\n",
    "               target_labels = labels[:, target_label_idx].to(device)\n",
    "               outputs = model(images)\n",
    "               \n",
    "               # 차원 처리\n",
    "               if len(outputs.shape) == 2:\n",
    "                   outputs = outputs.squeeze(1)\n",
    "               \n",
    "               preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "               \n",
    "               all_preds.append(preds.cpu().numpy().reshape(-1))\n",
    "               all_labels.append(target_labels.cpu().numpy().reshape(-1))\n",
    "           \n",
    "           else:\n",
    "               # 다중 레이블 케이스\n",
    "               target_labels = labels[:, target_label_idx].to(device)\n",
    "               outputs = model(images)\n",
    "               \n",
    "               # 각 레이블에 대한 예측\n",
    "               preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "               \n",
    "               all_preds.append(preds.cpu().numpy())\n",
    "               all_labels.append(target_labels.cpu().numpy())\n",
    "   \n",
    "   # numpy array로 변환\n",
    "   all_preds = np.concatenate(all_preds)\n",
    "   all_labels = np.concatenate(all_labels)\n",
    "   \n",
    "   if num_targets == 1:\n",
    "       # 단일 레이블 메트릭\n",
    "       f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "       accuracy = accuracy_score(all_labels, all_preds)\n",
    "       precision = precision_score(all_labels, all_preds)\n",
    "       recall = recall_score(all_labels, all_preds)\n",
    "       \n",
    "       return f1, accuracy, precision, recall\n",
    "   else:\n",
    "       # 다중 레이블 메트릭\n",
    "       f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "       accuracy = accuracy_score(all_labels, all_preds)\n",
    "       precision = precision_score(all_labels, all_preds, average='macro')\n",
    "       recall = recall_score(all_labels, all_preds, average='macro')\n",
    "       \n",
    "       return f1, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scaler, device, epochs, target_label_idx):\n",
    "    best_f1 = 0.0\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    num_targets = len(target_label_idx)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device, target_label_idx)\n",
    "        \n",
    "        if num_targets == 1:\n",
    "            val_f1, val_acc, val_prec, val_rec = evaluate(model, val_loader, device, target_label_idx)\n",
    "            \n",
    "            print(f\"Training Loss: {train_loss:.4f}\")\n",
    "            print(f\"Validation Metrics:\")\n",
    "            print(f\"  F1 Score: {val_f1:.4f}\")\n",
    "            print(f\"  Accuracy: {val_acc:.4f}\") \n",
    "            print(f\"  Precision: {val_prec:.4f}\")\n",
    "            print(f\"  Recall: {val_rec:.4f}\")\n",
    "            \n",
    "            scheduler.step(val_f1)\n",
    "            \n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f'model/singlelabel/best_model_label_{target_label_idx[0]}_nmc_cnn.pth')\n",
    "                print(\"New best model saved!\")\n",
    "        else:\n",
    "            # 모든 메트릭을 받아서 f1만 사용\n",
    "            val_f1, val_acc, val_prec, val_rec = evaluate(model, val_loader, device, target_label_idx)\n",
    "            \n",
    "            print(f\"Training Loss: {train_loss:.4f}\")\n",
    "            print(f\"Validation Metrics:\")\n",
    "            print(f\"  Macro F1 Score: {val_f1:.4f}\")\n",
    "            print(f\"  Macro Accuracy: {val_acc:.4f}\")\n",
    "            print(f\"  Macro Precision: {val_prec:.4f}\")\n",
    "            print(f\"  Macro Recall: {val_rec:.4f}\")\n",
    "            \n",
    "            scheduler.step(val_f1)\n",
    "            \n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f'model/singlelabel/best_model_labels_{\"-\".join(map(str,target_label_idx))}_nmc_cnn.pth')\n",
    "                print(\"New best model saved!\")\n",
    "        \n",
    "        early_stopping(val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:1\n",
      "/data/nmc/processed_image/cropped_images_1424x1648\n",
      "(0,)               1935\n",
      "(3,)                542\n",
      "(1, 2, 3)           532\n",
      "(1, 2)              286\n",
      "(2,)                233\n",
      "(1, 2, 3, 4)        190\n",
      "(2, 3)              163\n",
      "(1,)                155\n",
      "(4,)                 47\n",
      "(1, 3)               31\n",
      "(1, 2, 4)            27\n",
      "(3, 4)               22\n",
      "(1, 2, 3, 4, 5)      11\n",
      "(5,)                  9\n",
      "(2, 3, 4)             9\n",
      "(1, 4)                9\n",
      "(1, 2, 3, 5)          8\n",
      "(1, 2, 5)             7\n",
      "(2, 4)                7\n",
      "(1, 2, 3, 5, 6)       5\n",
      "(1, 2, 3, 6)          4\n",
      "(1, 3, 4)             2\n",
      "(1, 3, 6)             1\n",
      "(6,)                  1\n",
      "(1, 2, 6)             1\n",
      "(1, 2, 3, 4, 6)       1\n",
      "Name: label, dtype: int64\n",
      "train size: 4238\n",
      "(0,)               415\n",
      "(3,)               118\n",
      "(1, 2, 3)          113\n",
      "(1, 2)              65\n",
      "(2,)                50\n",
      "(1, 2, 3, 4)        46\n",
      "(2, 3)              35\n",
      "(1,)                32\n",
      "(4,)                13\n",
      "(1, 3)               7\n",
      "(5,)                 4\n",
      "(3, 4)               3\n",
      "(1, 2, 4)            2\n",
      "(1, 4)               2\n",
      "(2, 4)               2\n",
      "(1, 5)               2\n",
      "(1, 2, 3, 4, 6)      1\n",
      "(2, 3, 4)            1\n",
      "(1, 2, 3, 6)         1\n",
      "(1, 2, 3, 5)         1\n",
      "(1, 2, 5)            1\n",
      "Name: label, dtype: int64\n",
      "val size: 914\n",
      "(0,)            415\n",
      "(1, 2, 3)       114\n",
      "(3,)            108\n",
      "(1, 2)           67\n",
      "(2, 3)           41\n",
      "(1, 2, 3, 4)     40\n",
      "(2,)             40\n",
      "(1,)             24\n",
      "(1, 3)           11\n",
      "(3, 4)            8\n",
      "(2, 4)            7\n",
      "(1, 4)            6\n",
      "(5,)              5\n",
      "(1, 2, 4)         5\n",
      "(6,)              3\n",
      "(4,)              2\n",
      "(1, 2, 3, 5)      2\n",
      "(1, 3, 4)         1\n",
      "(2, 3, 4)         1\n",
      "(1, 2, 5)         1\n",
      "(1, 5)            1\n",
      "Name: label, dtype: int64\n",
      "test size: 902\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "best_mf1 = 0.0\n",
    "device = torch.device(cfg['DEVICE'])\n",
    "device = \"cuda:1\"\n",
    "print(\"device : \", device)\n",
    "num_workers = mp.cpu_count()\n",
    "train_cfg, eval_cfg = cfg['TRAIN'], cfg['EVAL']\n",
    "dataset_cfg, model_cfg = cfg['DATASET'], cfg['MODEL']\n",
    "loss_cfg, optim_cfg, sched_cfg = cfg['LOSS'], cfg['OPTIMIZER'], cfg['SCHEDULER']\n",
    "epochs, lr = train_cfg['EPOCHS'], optim_cfg['LR']\n",
    "\n",
    "image_size = [256,256]\n",
    "image_dir = Path(dataset_cfg['ROOT']) / 'train_images'\n",
    "train_transform = get_train_augmentation(image_size)\n",
    "val_test_transform = get_val_test_transform(image_size)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataset = eval(dataset_cfg['NAME'])(\n",
    "    dataset_cfg['ROOT'] + '/cropped_images_1424x1648',\n",
    "    dataset_cfg['TRAIN_RATIO'],\n",
    "    dataset_cfg['VALID_RATIO'],\n",
    "    dataset_cfg['TEST_RATIO'],\n",
    "    transform=None\n",
    ")\n",
    "trainset, valset, testset = dataset.get_splits()\n",
    "valset.transform = val_test_transform\n",
    "testset.transform = val_test_transform\n",
    "\n",
    "# trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=1, num_workers=1, pin_memory=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import os\n",
    "def denormalize(tensor):\n",
    "   \"\"\"Denormalize the image tensor\"\"\"\n",
    "   mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "   std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "   return tensor * std + mean\n",
    "\n",
    "def occlusion_sensitivity_map(model, image, target_label_idx, patch_size=14, stride=7, device='cuda'):\n",
    "    model.eval()\n",
    "    height, width = image.shape[-2:]\n",
    "    sensitivity_map = torch.zeros((height, width), device=device)\n",
    "    \n",
    "    # 타겟 인덱스 처리 수정\n",
    "    if isinstance(target_label_idx, list):\n",
    "        target_idx = target_label_idx[0]\n",
    "    else:\n",
    "        target_idx = target_label_idx\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        base_output = model(image.unsqueeze(0))\n",
    "        base_pred = torch.sigmoid(base_output)[0, target_idx].item()\n",
    "   \n",
    "    # 패치 단위로 가리며 예측값 변화 측정\n",
    "    for y in range(0, height-patch_size+1, stride):\n",
    "        for x in range(0, width-patch_size+1, stride):\n",
    "            occluded = image.clone()\n",
    "            occluded[..., y:y+patch_size, x:x+patch_size] = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(occluded.unsqueeze(0))\n",
    "                pred = torch.sigmoid(output)[0, target_label_idx].item()\n",
    "            \n",
    "            diff = abs(base_pred - pred)\n",
    "            sensitivity_map[y:y+patch_size, x:x+patch_size] += diff\n",
    "            \n",
    "    # 정규화\n",
    "    sensitivity_map = (sensitivity_map - sensitivity_map.min()) / (sensitivity_map.max() - sensitivity_map.min() + 1e-8)\n",
    "    return sensitivity_map.cpu().numpy()\n",
    "\n",
    "def create_comparison_image(original_img, nmc_heatmap, aptos_heatmap, label_info, nmc_correct, aptos_correct, save_path):\n",
    "   # Denormalize the original image\n",
    "   orig_img = denormalize(torch.from_numpy(original_img)).numpy()\n",
    "   orig_img = np.clip(orig_img.transpose(1, 2, 0), 0, 1)\n",
    "   orig_img = np.uint8(orig_img * 255)\n",
    "   \n",
    "   # Create heatmap overlays\n",
    "   nmc_heatmap_rgb = np.uint8(255 * nmc_heatmap)\n",
    "   nmc_heatmap_rgb = cv2.applyColorMap(nmc_heatmap_rgb, cv2.COLORMAP_JET)\n",
    "   nmc_superimposed = cv2.addWeighted(orig_img, 0.6, nmc_heatmap_rgb, 0.4, 0)\n",
    "   \n",
    "   aptos_heatmap_rgb = np.uint8(255 * aptos_heatmap)\n",
    "   aptos_heatmap_rgb = cv2.applyColorMap(aptos_heatmap_rgb, cv2.COLORMAP_JET)\n",
    "   aptos_superimposed = cv2.addWeighted(orig_img, 0.6, aptos_heatmap_rgb, 0.4, 0)\n",
    "   \n",
    "   # Create a white background for label info\n",
    "   height, width = orig_img.shape[:2]\n",
    "   info_height = height // 2  # 라벨 정보 영역의 높이를 절반으로\n",
    "   info_bg = np.ones((info_height, width * 3, 3), dtype=np.uint8) * 255  # 3배 너비\n",
    "   \n",
    "   # Add text to info background\n",
    "   font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "   font_scale = 0.5  # 글씨 크기 축소\n",
    "   thickness = 1\n",
    "   color = (0, 0, 0)  # Black color\n",
    "   \n",
    "   # Add label information\n",
    "   y_offset = 20\n",
    "   for line in label_info:\n",
    "       text_size = cv2.getTextSize(line, font, font_scale, thickness)[0]\n",
    "       x = (info_bg.shape[1] - text_size[0]) // 2\n",
    "       y = y_offset\n",
    "       cv2.putText(info_bg, line, (x, y), font, font_scale, color, thickness)\n",
    "       y_offset += 20\n",
    "   \n",
    "   # Create result texts\n",
    "   nmc_result = \"NMC: Correct\" if nmc_correct else \"NMC: Incorrect\"\n",
    "   aptos_result = \"APTOS: Correct\" if aptos_correct else \"APTOS: Incorrect\"\n",
    "   \n",
    "   # Add model results with color coding\n",
    "   text_size = cv2.getTextSize(nmc_result, font, font_scale, thickness)[0]\n",
    "   x = width + (width - text_size[0]) // 2\n",
    "   y = height // 2 - 20\n",
    "   color = (0, 255, 0) if nmc_correct else (0, 0, 255)\n",
    "   cv2.putText(info_bg, nmc_result, (x, y), font, font_scale, color, thickness)\n",
    "   \n",
    "   text_size = cv2.getTextSize(aptos_result, font, font_scale, thickness)[0]\n",
    "   x = 2 * width + (width - text_size[0]) // 2\n",
    "   color = (0, 255, 0) if aptos_correct else (0, 0, 255)\n",
    "   cv2.putText(info_bg, aptos_result, (x, y), font, font_scale, color, thickness)\n",
    "   \n",
    "   # Concatenate images horizontally\n",
    "   images_row = np.concatenate([orig_img, nmc_superimposed, aptos_superimposed], axis=1)\n",
    "   \n",
    "   # Concatenate info and images vertically\n",
    "   final_image = np.concatenate([info_bg, images_row], axis=0)\n",
    "   \n",
    "   # Save the final image\n",
    "   cv2.imwrite(save_path, cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def compare_and_save_gradcam(nmc_model, aptos_model, dataloader, nmc_label_idx, aptos_label_idx, device, save_dir='osm_results'):\n",
    "   nmc_model.eval()\n",
    "   aptos_model.eval()\n",
    "   \n",
    "   both_correct = []\n",
    "   only_nmc_correct = []\n",
    "   only_aptos_correct = []\n",
    "   both_wrong = []\n",
    "   \n",
    "   save_path = f\"{save_dir}/comparison/label_{'-'.join(map(str, nmc_label_idx))}_vs_{aptos_label_idx}\"\n",
    "   os.makedirs(save_path, exist_ok=True)\n",
    "   \n",
    "   with torch.no_grad():\n",
    "       for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "           images = images.to(device)\n",
    "           labels = labels.to(device)\n",
    "           \n",
    "           # APTOS model predictions (기준)\n",
    "           aptos_outputs = aptos_model(images)\n",
    "           aptos_predictions = (torch.sigmoid(aptos_outputs) > 0.5).squeeze()\n",
    "           aptos_raw_preds = torch.sigmoid(aptos_outputs).squeeze()\n",
    "           aptos_targets = labels[:, aptos_label_idx]\n",
    "           \n",
    "           # NMC model predictions\n",
    "           nmc_outputs = nmc_model(images)\n",
    "           nmc_predictions = (torch.sigmoid(nmc_outputs) > 0.5)\n",
    "           nmc_raw_preds = torch.sigmoid(nmc_outputs)\n",
    "           \n",
    "           # APTOS 라벨을 기준으로 NMC 예측 평가\n",
    "           nmc_correct = torch.where(\n",
    "               aptos_targets == 1,\n",
    "               torch.all(nmc_predictions == 1, dim=1),  # APTOS가 1일 때\n",
    "               torch.all(nmc_predictions == 0, dim=1)   # APTOS가 0일 때\n",
    "           )\n",
    "           \n",
    "           # Handle batch size 1 case\n",
    "           if len(images) == 1:\n",
    "               aptos_predictions = aptos_predictions.unsqueeze(0)\n",
    "               aptos_raw_preds = aptos_raw_preds.unsqueeze(0)\n",
    "               aptos_targets = aptos_targets.unsqueeze(0)\n",
    "               nmc_correct = nmc_correct.unsqueeze(0)\n",
    "           \n",
    "           for i in range(len(images)):\n",
    "               try:\n",
    "                   aptos_correct = (aptos_predictions[i].item() == aptos_targets[i].item())\n",
    "                   nmc_is_correct = nmc_correct[i].item()\n",
    "                   \n",
    "                   sample_info = {\n",
    "                       'image': images[i],\n",
    "                       'aptos_target': aptos_targets[i].item(),\n",
    "                       'nmc_preds': nmc_raw_preds[i].cpu().numpy(),\n",
    "                       'aptos_pred': aptos_raw_preds[i].item()\n",
    "                   }\n",
    "                   \n",
    "                   # Categorize samples\n",
    "                   if aptos_correct and nmc_is_correct and len(both_correct) < 3:\n",
    "                       both_correct.append(sample_info)\n",
    "                   elif not aptos_correct and nmc_is_correct and len(only_nmc_correct) < 3:\n",
    "                       only_nmc_correct.append(sample_info)\n",
    "                   elif aptos_correct and not nmc_is_correct and len(only_aptos_correct) < 3:\n",
    "                       only_aptos_correct.append(sample_info)\n",
    "                   elif not aptos_correct and not nmc_is_correct and len(both_wrong) < 3:\n",
    "                       both_wrong.append(sample_info)\n",
    "               \n",
    "               except Exception as e:\n",
    "                   print(f\"Error processing sample {i} in batch {batch_idx}: {e}\")\n",
    "                   continue\n",
    "               \n",
    "               if (len(both_correct) >= 3 and \n",
    "                   len(only_nmc_correct) >= 3 and \n",
    "                   len(only_aptos_correct) >= 3 and \n",
    "                   len(both_wrong) >= 3):\n",
    "                   break\n",
    "                   \n",
    "           if (len(both_correct) >= 3 and \n",
    "               len(only_nmc_correct) >= 3 and \n",
    "               len(only_aptos_correct) >= 3 and \n",
    "               len(both_wrong) >= 3):\n",
    "               break\n",
    "   \n",
    "   print(f\"\\nSamples collected:\")\n",
    "   print(f\"Both correct: {len(both_correct)}\")\n",
    "   print(f\"Only NMC correct: {len(only_nmc_correct)}\")\n",
    "   print(f\"Only APTOS correct: {len(only_aptos_correct)}\")\n",
    "   print(f\"Both wrong: {len(both_wrong)}\")\n",
    "   \n",
    "   # Save GradCAM visualizations for all categories\n",
    "   for category, samples, category_name in [\n",
    "       (both_correct, \"both_correct\", \"Both Correct\"),\n",
    "       (only_nmc_correct, \"only_nmc\", \"Only NMC Correct\"),\n",
    "       (only_aptos_correct, \"only_aptos\", \"Only APTOS Correct\"),\n",
    "       (both_wrong, \"both_wrong\", \"Both Wrong\")\n",
    "   ]:\n",
    "       for idx, sample in enumerate(category):\n",
    "           try:\n",
    "               nmc_heatmap = occlusion_sensitivity_map(nmc_model, sample['image'], nmc_label_idx[0], device=device)\n",
    "               aptos_heatmap = occlusion_sensitivity_map(aptos_model, sample['image'], 0, device=device)\n",
    "\n",
    "               \n",
    "               # Prepare label info\n",
    "               nmc_pred_str = np.array2string(sample['nmc_preds'], precision=3)\n",
    "               aptos_pred_str = f\"{sample['aptos_pred']:.3f}\"\n",
    "               aptos_target_str = f\"{int(sample['aptos_target'])}\"\n",
    "               \n",
    "               nmc_is_correct = torch.all(torch.tensor(sample['nmc_preds'] > 0.5) == (sample['aptos_target'] == 1))\n",
    "               aptos_is_correct = (sample['aptos_pred'] > 0.5) == sample['aptos_target']\n",
    "               \n",
    "               label_info = [\n",
    "                   f\"Category: {category_name}\",\n",
    "                   f\"NMC Labels: {nmc_label_idx}, APTOS Label: {aptos_label_idx}\",\n",
    "                   f\"APTOS - True: {aptos_target_str}, Pred: {aptos_pred_str}\",\n",
    "                   f\"NMC Predictions: {nmc_pred_str}\"\n",
    "               ]\n",
    "               \n",
    "               # Save combined result\n",
    "               save_name = os.path.join(save_path, f'{category_name.lower().replace(\" \", \"_\")}_{idx}.png')\n",
    "               create_comparison_image(\n",
    "                   sample['image'].cpu().numpy(),\n",
    "                   nmc_heatmap,\n",
    "                   aptos_heatmap,\n",
    "                   label_info,\n",
    "                   nmc_is_correct,\n",
    "                   aptos_is_correct,\n",
    "                   save_name\n",
    "               )\n",
    "               \n",
    "           except Exception as e:\n",
    "               print(f\"Error processing {category_name} sample {idx}: {e}\")\n",
    "               print(f\"Sample info: {sample}\")\n",
    "               continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NMC label [0] and APTOS label 0\n",
      "\n",
      "Samples collected:\n",
      "Both correct: 3\n",
      "Only NMC correct: 3\n",
      "Only APTOS correct: 3\n",
      "Both wrong: 3\n",
      "\n",
      "Processing NMC label [2] and APTOS label 1\n",
      "\n",
      "Samples collected:\n",
      "Both correct: 3\n",
      "Only NMC correct: 3\n",
      "Only APTOS correct: 3\n",
      "Both wrong: 3\n",
      "Error processing Both Correct sample 0: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0494, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0494, -2.0837,  ..., -2.0665, -2.0665, -2.0837]],\n",
      "\n",
      "        [[-2.0007, -2.0357, -2.0182,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0007]],\n",
      "\n",
      "        [[-1.7696, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7522, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7696, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7522, -1.7696,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00071884], dtype=float32), 'aptos_pred': 0.004073061048984528}\n",
      "Error processing Both Correct sample 1: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0665, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7522,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7347, -1.7522, -1.7522],\n",
      "         [-1.7696, -1.7870, -1.7522,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00011042], dtype=float32), 'aptos_pred': 0.22131064534187317}\n",
      "Error processing Both Correct sample 2: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.0665, -2.0837,  ..., -2.0837, -2.0665, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0007, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0182, -2.0007, -2.0182]],\n",
      "\n",
      "        [[-1.7522, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7347, -1.7347,  ..., -1.7696, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7696,  ..., -1.7870, -1.7696, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.0025257], dtype=float32), 'aptos_pred': 0.01003918144851923}\n",
      "Error processing Only NMC Correct sample 0: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         ...,\n",
      "         [-2.1008, -2.0665, -2.1008,  ..., -2.0837, -2.1008, -2.1179],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.1008, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0665, -2.0837]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7522, -1.7347, -1.7522,  ..., -1.7696, -1.7870, -1.8044],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7696, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00167482], dtype=float32), 'aptos_pred': 0.9963610768318176}\n",
      "Error processing Only NMC Correct sample 1: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1179, -2.1008,  ..., -2.1008, -2.1179, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1179, -2.1008],\n",
      "         [-2.1179, -2.1179, -2.1008,  ..., -2.1008, -2.1179, -2.1008],\n",
      "         ...,\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.0665, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.1008, -2.0837]],\n",
      "\n",
      "        [[-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.8044, -1.7870,  ..., -1.7522, -1.8044, -1.7870],\n",
      "         [-1.7522, -1.7522, -1.7870,  ..., -1.7522, -1.8044, -1.7870],\n",
      "         [-1.8044, -1.8044, -1.7870,  ..., -1.7696, -1.8044, -1.7522],\n",
      "         ...,\n",
      "         [-1.7522, -1.7522, -1.7522,  ..., -1.7696, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7522, -1.7522],\n",
      "         [-1.7522, -1.7522, -1.7522,  ..., -1.7696, -1.7522, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([5.9916656e-05], dtype=float32), 'aptos_pred': 0.9968400001525879}\n",
      "Error processing Only NMC Correct sample 2: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1179, -2.1008],\n",
      "         [-2.1179, -2.1008, -2.1008,  ..., -2.1008, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.8044, -1.8044],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.8044, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7696, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.7522, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7522, -1.7870,  ..., -1.7870, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7522, -1.7696,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.03676577], dtype=float32), 'aptos_pred': 0.9991660118103027}\n",
      "Error processing Only APTOS Correct sample 0: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1008,  ..., -2.1179, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.1179,  ..., -2.1179, -2.0837, -2.1179],\n",
      "         [-2.1179, -2.1008, -2.1179,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1179, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0007, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.8044, -1.7696, -1.8044],\n",
      "         [-1.8044, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.999191], dtype=float32), 'aptos_pred': 0.0022612344473600388}\n",
      "Error processing Only APTOS Correct sample 1: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.1008, -2.0665],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0665,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0007, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7696, -1.7870,  ..., -1.7696, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7696, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.9835028], dtype=float32), 'aptos_pred': 0.00021817235392518342}\n",
      "Error processing Only APTOS Correct sample 2: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.99992454], dtype=float32), 'aptos_pred': 0.00806654617190361}\n",
      "Error processing Both Wrong sample 0: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.1179, -2.1179],\n",
      "         [-2.1008, -2.1179, -2.1008,  ..., -2.1008, -2.1008, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1008,  ..., -2.1008, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.1179, -2.1008, -2.1008,  ..., -2.1008, -2.1179, -2.1008]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.7696, -1.7696, -1.8044],\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7522],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.99885905], dtype=float32), 'aptos_pred': 0.9571388363838196}\n",
      "Error processing Both Wrong sample 1: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1008, -2.1179],\n",
      "         [-2.1179, -2.1008, -2.1179,  ..., -2.1179, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.1179, -2.1179,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.7870, -1.8044,  ..., -1.8044, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.8044, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7522,  ..., -1.7696, -1.7522, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.00055376], dtype=float32), 'aptos_pred': 0.0252348892390728}\n",
      "Error processing Both Wrong sample 2: index 2 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.1008, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0182, -2.0357, -2.0007,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7522, -1.7870],\n",
      "         [-1.7522, -1.7522, -1.7696,  ..., -1.7870, -1.7870, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.9258571], dtype=float32), 'aptos_pred': 0.5365992188453674}\n",
      "\n",
      "Processing NMC label [1] and APTOS label 2\n",
      "\n",
      "Samples collected:\n",
      "Both correct: 3\n",
      "Only NMC correct: 3\n",
      "Only APTOS correct: 3\n",
      "Both wrong: 3\n",
      "Error processing Both Correct sample 0: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0494, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0494, -2.0837,  ..., -2.0665, -2.0665, -2.0837]],\n",
      "\n",
      "        [[-2.0007, -2.0357, -2.0182,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0007]],\n",
      "\n",
      "        [[-1.7696, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7522, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7696, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7522, -1.7696,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00173314], dtype=float32), 'aptos_pred': 0.35526156425476074}\n",
      "Error processing Both Correct sample 1: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0665, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7522,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7347, -1.7522, -1.7522],\n",
      "         [-1.7696, -1.7870, -1.7522,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00051417], dtype=float32), 'aptos_pred': 0.1459483802318573}\n",
      "Error processing Both Correct sample 2: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.0665, -2.0837,  ..., -2.0837, -2.0665, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0007, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0182, -2.0007, -2.0182]],\n",
      "\n",
      "        [[-1.7522, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7347, -1.7347,  ..., -1.7696, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7696,  ..., -1.7870, -1.7696, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.00146461], dtype=float32), 'aptos_pred': 0.022741960361599922}\n",
      "Error processing Only NMC Correct sample 0: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.1179, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0007, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7522, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.9545111], dtype=float32), 'aptos_pred': 0.28662651777267456}\n",
      "Error processing Only NMC Correct sample 1: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1008,  ..., -2.1179, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.1179,  ..., -2.1179, -2.0837, -2.1179],\n",
      "         [-2.1179, -2.1008, -2.1179,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1179, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0007, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.8044, -1.7696, -1.8044],\n",
      "         [-1.8044, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.8983752], dtype=float32), 'aptos_pred': 0.11524824053049088}\n",
      "Error processing Only NMC Correct sample 2: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.1008, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0007, -2.0357, -2.0007],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0007]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7870, -1.7696],\n",
      "         [-1.7522, -1.7522, -1.7696,  ..., -1.7870, -1.7522, -1.7347]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.9201024], dtype=float32), 'aptos_pred': 0.3875848054885864}\n",
      "Error processing Only APTOS Correct sample 0: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1179, -2.1179,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1179, -2.1179,  ..., -2.1008, -2.1008, -2.1179],\n",
      "         [-2.1008, -2.0665, -2.1008,  ..., -2.0837, -2.1179, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.1179, -2.0837],\n",
      "         [-2.1179, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.8044, -1.8044,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.8044, -1.8044,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.7696, -1.7870,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         [-1.8044, -1.7696, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.9992073], dtype=float32), 'aptos_pred': 0.4475078880786896}\n",
      "Error processing Only APTOS Correct sample 1: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([0.7246239], dtype=float32), 'aptos_pred': 0.016665814444422722}\n",
      "Error processing Only APTOS Correct sample 2: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.1316362], dtype=float32), 'aptos_pred': 0.7292776107788086}\n",
      "Error processing Both Wrong sample 0: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.1179, -2.1179],\n",
      "         [-2.1008, -2.1179, -2.1008,  ..., -2.1008, -2.1008, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1008,  ..., -2.1008, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.1179, -2.1008, -2.1008,  ..., -2.1008, -2.1179, -2.1008]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.7696, -1.7696, -1.8044],\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7522],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.03677505], dtype=float32), 'aptos_pred': 0.06997543573379517}\n",
      "Error processing Both Wrong sample 1: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.1179],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0665, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7870,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.00027532], dtype=float32), 'aptos_pred': 0.03338674455881119}\n",
      "Error processing Both Wrong sample 2: index 1 is out of bounds for dimension 1 with size 1\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.1008, -2.0665],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0665,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0007, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7696, -1.7870,  ..., -1.7696, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7696, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.44214302], dtype=float32), 'aptos_pred': 0.29504796862602234}\n",
      "\n",
      "Processing NMC label [1, 2] and APTOS label 3\n",
      "\n",
      "Samples collected:\n",
      "Both correct: 3\n",
      "Only NMC correct: 3\n",
      "Only APTOS correct: 3\n",
      "Both wrong: 3\n",
      "\n",
      "Processing NMC label [5, 6] and APTOS label 4\n",
      "\n",
      "Samples collected:\n",
      "Both correct: 3\n",
      "Only NMC correct: 3\n",
      "Only APTOS correct: 3\n",
      "Both wrong: 3\n",
      "Error processing Both Correct sample 0: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0494, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0494, -2.0665, -2.0837],\n",
      "         [-2.0665, -2.0494, -2.0837,  ..., -2.0665, -2.0665, -2.0837]],\n",
      "\n",
      "        [[-2.0007, -2.0357, -2.0182,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0007]],\n",
      "\n",
      "        [[-1.7696, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7522, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7696, -1.7696,  ..., -1.7696, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7522, -1.7696,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([1.7914674e-05, 1.5065243e-04], dtype=float32), 'aptos_pred': 1.475409953854978e-05}\n",
      "Error processing Both Correct sample 1: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0665, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0182, -2.0182]],\n",
      "\n",
      "        [[-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7522,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7347, -1.7522, -1.7522],\n",
      "         [-1.7696, -1.7870, -1.7522,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([2.6973135e-05, 2.4775579e-04], dtype=float32), 'aptos_pred': 0.0001255862443940714}\n",
      "Error processing Both Correct sample 2: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.1008, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.0665, -2.0837,  ..., -2.0837, -2.0665, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0007, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0007],\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0182, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0007, -2.0182,  ..., -2.0182, -2.0007, -2.0182]],\n",
      "\n",
      "        [[-1.7522, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7347, -1.7347,  ..., -1.7696, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7696,  ..., -1.7870, -1.7696, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([6.3471147e-05, 3.0976234e-04], dtype=float32), 'aptos_pred': 0.0012114992132410407}\n",
      "Error processing Only NMC Correct sample 0: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([3.5102989e-06, 1.2845045e-04], dtype=float32), 'aptos_pred': 0.9997667670249939}\n",
      "Error processing Only NMC Correct sample 1: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.1008, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.1008]],\n",
      "\n",
      "        [[-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0007],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7522,  ..., -1.7696, -1.7347, -1.7522],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([2.0425518e-05, 8.1650884e-05], dtype=float32), 'aptos_pred': 0.9993634819984436}\n",
      "Error processing Only NMC Correct sample 2: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0665],\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.0665, -2.0837,  ..., -2.0494, -2.0837, -2.0665],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0665, -2.0665,  ..., -2.0665, -2.0837, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0007, -2.0182, -2.0182],\n",
      "         [-2.0007, -2.0357, -2.0357,  ..., -2.0182, -2.0007, -2.0357],\n",
      "         [-2.0182, -2.0182, -2.0007,  ..., -2.0182, -2.0007, -2.0182]],\n",
      "\n",
      "        [[-1.7522, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7696],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7522, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7347, -1.7696,  ..., -1.7522, -1.7696, -1.7696],\n",
      "         [-1.7696, -1.7522, -1.7870,  ..., -1.7696, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.7347, -1.7696,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([2.7202086e-06, 7.3671523e-05], dtype=float32), 'aptos_pred': 0.9999544620513916}\n",
      "Error processing Only APTOS Correct sample 0: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1179, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.0837, -2.1008, -2.0837],\n",
      "         [-2.1008, -2.1008, -2.0837,  ..., -2.1179, -2.1008, -2.1179],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0665,  ..., -2.0665, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         [-1.8044, -1.7870, -1.7870,  ..., -1.8044, -1.7870, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7522, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7522, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7522, -1.7696,  ..., -1.7522, -1.7870, -1.7522]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([5.8764108e-06, 1.3533921e-04], dtype=float32), 'aptos_pred': 0.6879509687423706}\n",
      "Error processing Only APTOS Correct sample 1: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.1008, -2.1179],\n",
      "         [-2.0837, -2.1179, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0665, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0665, -2.0837,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0007, -2.0182,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0007, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.7870, -1.7696, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7696, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7522, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7696,  ..., -1.7696, -1.7347, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7522, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([1.7117605e-06, 8.7088072e-01], dtype=float32), 'aptos_pred': 0.006463630590587854}\n",
      "Error processing Only APTOS Correct sample 2: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.0837, -2.0837,  ..., -2.1008, -2.1179, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.8044, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 0.0, 'nmc_preds': array([9.9989736e-01, 4.7766887e-05], dtype=float32), 'aptos_pred': 0.053020283579826355}\n",
      "Error processing Both Wrong sample 0: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1008, -2.1179],\n",
      "         [-2.1179, -2.1008, -2.1179,  ..., -2.1179, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.1179, -2.1179,  ..., -2.1008, -2.1008, -2.1008],\n",
      "         ...,\n",
      "         [-2.0837, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0665, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0182, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0007, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.7870, -1.8044],\n",
      "         [-1.8044, -1.7870, -1.8044,  ..., -1.8044, -1.7696, -1.7870],\n",
      "         [-1.7870, -1.8044, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7522,  ..., -1.7696, -1.7522, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([1.9505673e-05, 1.0463663e-04], dtype=float32), 'aptos_pred': 0.0016108488198369741}\n",
      "Error processing Both Wrong sample 1: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         ...,\n",
      "         [-2.0837, -2.1008, -2.1008,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0665, -2.0665,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.0837, -2.0837,  ..., -2.0665, -2.0665, -2.0837]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0007,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0182, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.8044,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.7696,  ..., -1.7696, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7696, -1.7696, -1.7870]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([0.00021866, 0.00025922], dtype=float32), 'aptos_pred': 0.0003247543063480407}\n",
      "Error processing Both Wrong sample 2: index 5 is out of bounds for dimension 1 with size 2\n",
      "Sample info: {'image': tensor([[[-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.1008],\n",
      "         [-2.1008, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.1008, -2.0837, -2.1008],\n",
      "         ...,\n",
      "         [-2.1008, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837],\n",
      "         [-2.1008, -2.0837, -2.1008,  ..., -2.0665, -2.0837, -2.0837],\n",
      "         [-2.0837, -2.1008, -2.0837,  ..., -2.0837, -2.0837, -2.0665]],\n",
      "\n",
      "        [[-2.0357, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0182],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0182, -2.0357, -2.0007,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0182]],\n",
      "\n",
      "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7522, -1.7522],\n",
      "         [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "         ...,\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7870, -1.7870, -1.7696,  ..., -1.7696, -1.7522, -1.7870],\n",
      "         [-1.7522, -1.7522, -1.7696,  ..., -1.7870, -1.7870, -1.7696]]],\n",
      "       device='cuda:1'), 'aptos_target': 1.0, 'nmc_preds': array([5.1433485e-06, 1.5204621e-04], dtype=float32), 'aptos_pred': 2.6800165869644843e-05}\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "nmc_labels = [[0],[2],[1],[1,2],[5,6]]\n",
    "aptos_labels = [0,1,2,3,4]  # 각각 대응되는 APTOS 라벨\n",
    "\n",
    "for idx, nmc_label_idx in enumerate(nmc_labels):\n",
    "   aptos_label_idx = aptos_labels[idx]\n",
    "   \n",
    "   print(f\"\\nProcessing NMC label {nmc_label_idx} and APTOS label {aptos_label_idx}\")\n",
    "   \n",
    "   # Load NMC model\n",
    "   nmc_model = models.efficientnet_v2_m(pretrained=True)\n",
    "   num_ftrs = nmc_model.classifier[1].in_features\n",
    "   nmc_model.classifier = nn.Sequential(\n",
    "       nn.BatchNorm1d(num_ftrs),\n",
    "       nn.Linear(num_ftrs, len(nmc_label_idx))\n",
    "   )\n",
    "   nmc_model = nmc_model.to(device)\n",
    "   \n",
    "   if len(nmc_label_idx)==1:\n",
    "       nmc_model.load_state_dict(torch.load(f'model/singlelabel/best_model_label_{nmc_label_idx[0]}_nmc_cnn.pth'))\n",
    "   else:\n",
    "       nmc_model.load_state_dict(torch.load(f'model/singlelabel/best_model_labels_{\"-\".join(map(str,nmc_label_idx))}_nmc_cnn.pth'))\n",
    "   \n",
    "   # Load APTOS model\n",
    "   aptos_model = models.efficientnet_v2_m(pretrained=True)\n",
    "   aptos_model.classifier = nn.Sequential(\n",
    "       nn.BatchNorm1d(num_ftrs),\n",
    "       nn.Linear(num_ftrs, 1)\n",
    "   )\n",
    "   aptos_model = aptos_model.to(device)\n",
    "   aptos_model.load_state_dict(torch.load(f'model/singlelabel/best_model_label_{aptos_label_idx}_aptos_cnn.pth'))\n",
    "   \n",
    "   # Compare and save results\n",
    "   compare_and_save_gradcam(nmc_model, aptos_model, testloader, nmc_label_idx, aptos_label_idx, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
